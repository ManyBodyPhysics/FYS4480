
!split
===== Discussion: Consequences of HK Theorems =====

DFT exists in principle: HK1 establishes that the ground-state density is as fundamental as the wavefunction – it encapsulates all the information needed to determine the system’s Hamiltonian and thus all ground-state observables. This is a remarkable reduction: instead of a complicated wavefunction $\Psi$, we can work with $n(\mathbf{r})$.
Energy as a functional of density: HK2 guarantees an energy functional $E[n]$ exists. However, the theorems themselves do not provide an explicit form for $F[n] = T[n] + V_{\rm int}[n]$. They are existence theorems. The challenge of DFT (and much of this course) is how to approximate $F[n]$ in practice, especially the many-body terms hidden in it.
Variational principle: Given HK2, one can variationally obtain the ground state: if we had the exact $E[n]$ functional, minimizing $E[n]$ with respect to $n(\mathbf{r})$ (subject to $\int n(\mathbf{r}) d^3r = N$) yields the true ground-state density and energy. In formal terms, $\delta {E[n] - \mu(\int n - N)} / \delta n(\mathbf{r}) = 0$ leads to a condition $\frac{\delta E[n]}{\delta n(\mathbf{r})}\big|_{n=n_0} = \mu$ (constant Fermi level $\mu$ for the ground state).
Proof sketch of HK Theorem I: It’s instructive to see why two different potentials cannot give the same density. Suppose $V_{\rm ext}^{(1)}(\mathbf{r})$ and $V_{\rm ext}^{(2)}(\mathbf{r})$ yield the same ground-state density $n(\mathbf{r})$ but different ground-state wavefunctions $\Psi^{(1)}$ and $\Psi^{(2)}$. Let $E^{(1)}$ and $E^{(2)}$ be their ground-state energies. Without loss of generality, assume $E^{(1)} < E^{(2)}$. Then, using $\Psi^{(2)}$ in Hamiltonian 1: $E^{(1)} < \langle \Psi^{(2)}|\hat{H}^{(1)}|\Psi^{(2)}\rangle = \langle \Psi^{(2)}|\hat{H}^{(2)}|\Psi^{(2)}\rangle + \int [V_{\rm ext}^{(1)}(\mathbf{r})-V_{\rm ext}^{(2)}(\mathbf{r})],n(\mathbf{r}),d^3r = E^{(2)} + \int [V_{\rm ext}^{(1)}-V_{\rm ext}^{(2)}] n(\mathbf{r})$ . Similarly, exchanging 1↔2 leads to $E^{(2)} < E^{(1)} + \int [V_{\rm ext}^{(2)}-V_{\rm ext}^{(1)}] n(\mathbf{r})$ . Adding these two inequalities yields $E^{(1)} + E^{(2)} < E^{(1)} + E^{(2)}$, a contradiction. Thus $V_{\rm ext}^{(1)}$ and $V_{\rm ext}^{(2)}$ cannot produce the same $n(\mathbf{r})$. This proves the uniqueness (HK1).
Domain and $v$-representability: Not every arbitrary $n(\mathbf{r})$ is a valid ground-state density of some physical $V_{\rm ext}$ (this is the issue of $v$-representability). HK theorems assume $n(\mathbf{r})$ comes from some ground state of a Hamiltonian. Modern proofs (Levy–Lieb constrained search) circumvent some $v$-representability issues by considering minimization over all wavefunctions yielding a density $n$.
Implications: The ground-state energy can be obtained in principle by minimizing $E[n]$. However, without an expression for $F[n]$, one cannot perform this minimization in practice. Enter the Kohn–Sham approach (see below), which provides a clever way to approximate $F[n]$ using orbitals. 

!split
===== Example: Thomas–Fermi Approximation (Historical Perspective) =====

Before rigorous DFT, the Thomas–Fermi (TF) model (1927) was an early density-based theory. It modeled the kinetic energy of electrons in a homogeneous way: T_{\rm TF}[n] = \frac{3}{10}(3\pi^2)^{2/3} \int n^{5/3}(\mathbf{r})\,d^3r\,, and the electron–electron interaction via a Hartree term $E_{\rm H}[n] = \frac{e^2}{2}\int d^3r,d^3r’ ,\frac{n(\mathbf{r}),n(\mathbf{r}’)}{|\mathbf{r}-\mathbf{r}’|}$. The total TF energy functional: E_{\rm TF}[n] = T_{\rm TF}[n] + E_{\rm H}[n] + \int V_{\rm ext} n(\mathbf{r})\,d^3r\,. Minimizing $E_{\rm TF}[n]$ for atoms gives a rough electron density profile. However, TF theory neglects shell structure and chemical bonding entirely (no exchange or true fermionic kinetic energy oscillations).
Significance: TF theory does not produce bound molecules (it predicts atoms just barely unbound) , indicating that the simplistic functional misses important physics (exchange and quantum oscillations). Nonetheless, it was a foundation that showed the promise of using $n(\mathbf{r})$ and inspired the development of DFT.
Modern DFT vs. TF: The Kohn–Sham method can be viewed as incorporating the missing quantum effects by using an effective single-particle approach (coming next). In effect, Kohn–Sham splits $F[n]$ into a large known part (non-interacting kinetic energy + Hartree) and a smaller unknown remainder (exchange-correlation) that can be approximated.
Preview of next lecture: How can we find the correct density without knowing the exact $F[n]$? The answer is the Kohn–Sham scheme, which introduces a fictitious non-interacting system that reproduces the same density. This yields tractable equations for orbitals, which, when solved self-consistently, give the ground-state density and energy.

!split
===== Kohn–Sham Formalism, the ansatz =====


Challenge: The HK theorems ensure an energy functional exists but don’t tell us its form. Direct use of $E[n]$ is impractical without approximations for $F[n] = T[n] + V_{\rm int}[n]$. Early attempts (like Thomas–Fermi) were too crude. We need a more accurate scheme to handle the kinetic and interaction energies.
Kohn–Sham idea (1965): Instead of trying to directly approximate the many-body kinetic energy $T[n]$ for interacting electrons, Kohn and Sham proposed to replace the real interacting system by an auxiliary non-interacting system of electrons that yields the same density $n(\mathbf{r})$ as the true system  . This fictitious system is easier to solve (since non-interacting electrons just occupy orbitals).
We introduce $N$ single-particle orbitals ${\psi_i(\mathbf{r})}$ (for $i=1,\dots,N$ for a spin-unpolarized system; we will generalize to spin later) such that n(\mathbf{r}) = \sum_{i=1}^N |\psi_i(\mathbf{r})|^2\,, where each $\psi_i(\mathbf{r})$ is an orbital in the auxiliary system  . We assume these $N$ orbitals can be chosen as orthonormal and occupy the lowest $N$ energy levels of some effective single-particle Hamiltonian.
Non-interacting kinetic energy: We can exactly compute a kinetic energy for these orbitals: T_s[n] \equiv T_{\rm eff}[n] = -\frac{\hbar^2}{2m} \sum_{i=1}^N \int \psi_i^*(\mathbf{r})\,\nabla^2\,\psi_i(\mathbf{r})\,d^3r\,, which is the kinetic energy of non-interacting electrons with density $n(\mathbf{r})$ . $T_s[n]$ is generally not equal to the true kinetic energy $T[n]$ of the interacting system, but it will be the major part of it.
Decomposing the energy functional: We then write the total energy functional as E[n] = T_s[n] + E_{\rm H}[n] + E_{\rm xc}[n] + \int V_{\rm ext}(\mathbf{r})\,n(\mathbf{r})\,d^3r\,. Here $E_{\rm H}[n] = \frac{1}{2}\int!\int \frac{n(\mathbf{r}),n(\mathbf{r’})}{|\mathbf{r}-\mathbf{r’}|} d^3r,d^3r’$ is the classical Hartree (Coulomb) energy of the electron distribution, and $E_{\rm xc}[n]$ is defined as the exchange–correlation energy, which by construction includes all the many-body effects not captured by $T_s$ and $E_{\rm H}$【28†match】 (see below for formal definition).
Essentially, $E_{\rm xc}[n]$ is a correction term: E_{\rm xc}[n] \equiv (T[n] - T_s[n]) + (V_{\rm int}[n] - E_{\rm H}[n])\,, i.e. it contains the difference between the true kinetic energy and the non-interacting kinetic energy plus the difference between the true electron–electron interaction energy and the simple Hartree term . In this way, if $E_{\rm xc}[n]$ were known exactly, DFT would be exact. All approximation difficulty is shoved into $E_{\rm xc}$. 

!split
===== Derivation of the Kohn–Sham Equations (Variational Method) =====

We now minimize the energy functional $E[n]$ with respect to the orbitals $\psi_i(\mathbf{r})$, subject to the constraint that $\int |\psi_i|^2 = 1$ (orthonormality for different $i$). This is equivalent to minimizing w.r.t. $n(\mathbf{r})$ but using the orbital representation ensures $n(\mathbf{r})$ is $v$-representable by some non-interacting system.
The Kohn–Sham energy functional (including all terms) can be written as: E[n] = T_s[n] + \int V_{\rm ext}(r)\,n(r)\,dr + E_{\rm H}[n] + E_{\rm xc}[n]\,, where we treat $E_{\rm H}$ and $E_{\rm xc}$ as explicit functionals of $n$ (and thus implicit of ${\psi_i}$). For brevity, denote E_{\rm other}[n] \equiv \int V_{\rm ext} n\,dr + E_{\rm H}[n] + E_{\rm xc}[n]\,.
We impose orthonormality via Lagrange multipliers $\epsilon_j$ (which will turn out to be the orbital energies). The Euler–Lagrange equation for minimizing $E[{\psi_i}] = T_s[{\psi_i}] + E_{\rm other}[n]$ is: \frac{\delta}{\delta \psi_i^(r)} \Big\{ T_s[\{\psi\}] + E_{\rm other}[n] - \sum_{j}\epsilon_j (\langle\psi_j|\psi_j\rangle - 1)\Big\} = 0\,, for each $i$. Varying $\psi_i^$ yields: \frac{\delta T_s}{\delta \psi_i^(r)} + \int d^3r’\, \frac{\delta E_{\rm other}}{\delta n(r’)} \frac{\delta n(r’)}{\delta \psi_i^(r)} = \epsilon_i\,\psi_i(r)\,. Now, $\delta T_s/\delta \psi_i^* = -\frac{\hbar^2}{2m}\nabla^2 \psi_i(r)$ (like a kinetic operator acting on $\psi_i$), and $\frac{\delta E_{\rm other}}{\delta n(r’)} = V_{\rm ext}(r’) + \frac{\delta E_{\rm H}}{\delta n(r’)} + \frac{\delta E_{\rm xc}}{\delta n(r’)}$.
Note $\frac{\delta E_{\rm H}}{\delta n(r’)} = \int d^3r’’, \frac{n(r’’)}{|r’-r’’|} = V_{\rm H}(r’)$, the Hartree potential, and by definition $\frac{\delta E_{\rm xc}}{\delta n(r’)} = V_{\rm xc}(r’)$, the exchange–correlation potential. Also, $\frac{\delta n(r’)}{\delta \psi_i^*(r)} = \psi_i(r)\delta(r-r’)$ (since $n = \sum_j |\psi_j|^2$). So the variational equation becomes: -\frac{\hbar^2}{2m}\nabla^2\psi_i(r) + \Big[V_{\rm ext}(r) + V_{\rm H}(r) + V_{\rm xc}(r)\Big]\psi_i(r) = \epsilon_i\, \psi_i(r)\,. This is the Kohn–Sham equation  , which has the form of a one-particle Schrödinger equation: \hat{H}{\rm KS}\psi_i(r) = \epsilon_i \psi_i(r)\,, where $\hat{H}{\rm KS} = -\frac{\hbar^2}{2m}\nabla^2 + V_{\rm eff}(r)$ and V_{\rm eff}(r) = V_{\rm ext}(r) + V_{\rm H}n + V_{\rm xc}n\,. This effective potential $V_{\rm eff}(r)$ depends on the density $n(r)$ through $V_{\rm H}$ and $V_{\rm xc}$ .
We have obtained a set of $N$ coupled one-particle equations. The couplings are implicit: all orbitals $\psi_i$ feel the same $V_{\rm eff}[n]$, and $V_{\rm eff}$ in turn depends on all $\psi_i$ via $n(r) = \sum_{j}|\psi_j|^2$. Thus, the KS equations must be solved self-consistently. 

!split
===== Interpreting the Kohn–Sham Equations =====

Self-consistent field (SCF): The KS equations $(-\frac{\hbar^2}{2m}\nabla^2 + V_{\rm eff}n)\psi_i = \epsilon_i\psi_i$ look like independent-particle Schrödinger equations. However, $V_{\rm eff}(r)$ depends on $n(r)$, which in turn depends on all ${\psi_i}$. Solving them requires a self-consistent cycle: guess a density (or orbitals) $\rightarrow$ compute $V_{\rm eff}$ $\rightarrow$ solve for new $\psi_i$ $\rightarrow$ update $n(r)$ $\rightarrow$ repeat until convergence. (We will detail this algorithm in Lecture 4.)
Exchange–correlation potential: $V_{\rm xc}(r) = \delta E_{\rm xc}/\delta n(r)$ plays a central role. It includes all many-body effects such as exchange (Pauli exclusion) and electron correlation. In practice, $E_{\rm xc}[n]$ must be approximated. But if $E_{\rm xc}$ were known exactly, $V_{\rm xc}(r)$ ensures that the KS orbitals yield the correct $n(r)$ and energy.
Total energy expression: Once the KS equations are solved for the orbitals and eigenvalues, one can compute the total energy as E[n] = \sum_{i=1}^N \epsilon_i \;-\; \frac{1}{2}\int d^3r\, V_{\rm H}(r)\,n(r)\;+\; E_{\rm xc}[n] \;-\; \int d^3r\, n(r)\,V_{\rm xc}(r)\,. This formula corrects for the fact that $\sum_i \epsilon_i$ counts the Hartree energy and $E_{\rm xc}$ contributions in a non-double-counting way . It can be derived from the variation result and ensures adding $V_{\rm xc}$ term did not overcount those energies.
Physical meaning of $\epsilon_i$: The KS eigenvalues $\epsilon_i$ do not strictly equal the true excitation energies of the system (except in special cases). They are Lagrange multipliers to enforce orbital orthonormality. However, the highest occupied KS eigenvalue $\epsilon_{\rm HOMO}$ (for exact XC) equals the negative of the ionization energy by Janak’s theorem and the Koopmans’ theorem analogue in DFT. Also, differences $\epsilon_{i}-\epsilon_{j}$ often resemble quantum excitation energies (and in practice KS band structures often qualitatively match measured band structures, with notable systematic errors like band gap underestimation – more in Lecture 5).
Spin-generalization: Real systems have electron spin. Spin-DFT (or LSDA) extends KS to two densities: $n_\uparrow(r)$ and $n_\downarrow(r)$ for spin-up and spin-down electrons. The HK theorems generalize to spin densities, and one defines $E[n_\uparrow,n_\downarrow]$ with exchange-correlation functional $E_{\rm xc}[n_\uparrow,n_\downarrow]$. In practice, one often uses local spin-density approximation (LSDA) where $E_{\rm xc}$ depends on $n_\uparrow$ and $n_\downarrow$ locally. The KS equations split for each spin channel with their own $V_{\rm xc}^\uparrow$ and $V_{\rm xc}^\downarrow$. Exchange energy, for example, is computed separately for each spin as it involves like-spin correlations .
Summary: The Kohn–Sham formulation reduces the interacting $N$-electron problem to $N$ one-electron equations, provided we have a good approximation for $E_{\rm xc}[n]$. This was a monumental shift – it allows using basis sets and algorithms from one-particle quantum mechanics (like plane waves, etc.) to handle many-electron systems with reasonable cost. 



!split
===== The Exchange–Correlation Functional $E_{\xc}[n]$ =====

$E_{\xc}[n]$ is the heart of DFT approximations. It encodes all the many-body quantum effects beyond the simple Hartree picture and non-interacting kinetic energy. By definition: \[ E_{\xc}[n] = (T[n] - T_s[n]) + (V_{\rm int}[n] - E_{\rm H}[n])\,, \] which includes: – Exchange energy $E_x[n]$: the part arising from Pauli exclusion (present even in Hartree–Fock). – Correlation energy $E_c[n]$: the remaining part due to electron-electron dynamical correlations (not captured by a single Slater determinant).
The exact $E_{\xc}[n]$ is unknown except for simple model systems. We rely on approximate forms. Despite the word “exchange-correlation”, standard DFT approximations do not treat exchange and correlation separately; rather $E_{\xc}$ is an integrated functional typically constructed with certain properties in mind (sum rules, known limits, etc.).
Key properties of $E_{\xc}[n]$ (exact functional): 
$E_{\xc}$ is typically negative (exchange is negative, lowering energy; correlation usually negative as well for bound systems).
It has a corresponding potential $V_{\xc}(\mathbf{r}) = \delta E_{\xc}/\delta n(\mathbf{r})$. This $V_{\xc}$ ensures the KS orbitals yield the correct $n(\mathbf{r})$.
$E_{\xc}$ accounts for things like the exchange hole (the reduced probability of finding another electron near a given electron due to Pauli principle) and the correlation hole (avoidance due to Coulomb repulsion).
There is an important sum rule: the exchange hole integrated over space gives $-1$ electron (each electron excludes one charge of same-spin density around it).

Because the exact functional is intractable, we build approximations in a systematic way (sometimes called “Jacob’s ladder” of DFT approximations, from simplest to more complex forms).


!split
===== Local Density Approximation (LDA) =====

LDA formulation: The local density approximation is the first and simplest rung of approximations. In LDA, one assumes the XC energy at point $\mathbf{r}$ depends only on the local density $n(\mathbf{r})$. Specifically, \[ E_{\xc}^{\rm LDA}[n] = \int d^3r\, n(\mathbf{r})\, \varepsilon_{\xc}\!\big(n(\mathbf{r})\big)\,, \] where $\varepsilon_{\xc}(n)$ is the XC energy per electron of a uniform electron gas of density $n$. So essentially, LDA treats each point in the material as if it were part of a homogeneous electron gas with that local density.
Origin: The homogeneous electron gas (HEG) is one of the rare many-body systems we can solve (with quantum Monte Carlo, etc.). For a given uniform density $n$, the exchange energy per electron is known analytically (Dirac, 1930): \varepsilon_x(n) = -\frac{3}{4}\left(\frac{3}{\pi}\right)^{1/3} \frac{e^2 n^{1/3}}{4\pi\epsilon_0} \quad \text{(in SI units, or = $-0.458\, r_s^{-1}$ Ry in atomic units)}. The correlation energy per electron $\varepsilon_c(n)$ was tabulated via Monte Carlo by Ceperley and Alder (1980) and fit by Perdew–Zunger (1981) – providing a practical formula for $\varepsilon_c(n)$ for all densities.
Successes of LDA: In the 1970s–80s, LDA proved surprisingly successful for solids and simple metals. It tends to give reasonably good electron densities and total energies, often canceling errors between exchange and correlation. For many solids, LDA predicts lattice constants within a few percent of experiment and bulk modulus within ~10%. For example, LDA for silicon gives a lattice constant slightly smaller than experiment (overbinding), but within ~1-2% .
Systematic errors: LDA, however, is not very accurate for molecules (it overbinds molecules by about 1 eV per bond on average ). It also underestimates bond lengths (making them too short) and overestimates vibrational frequencies. In extended systems, LDA typically underestimates band gaps of semiconductors (often giving 30-50% smaller gaps or even falsely predicting a metallic state for some insulators).
Why LDA works or fails: LDA has no knowledge of density gradients or molecule-specific effects. It works best when the system’s density varies slowly or is close to homogeneous (like simple metals). It fails when density is highly inhomogeneous or when delicate bonding/angle preferences occur (where gradients matter) or in systems where long-range correlation (van der Waals) is important, since a uniform-gas approximation can’t capture those. 

!split
===== Generalized Gradient Approximation (GGA) =====

Inclusion of density gradients: The next rung beyond LDA are GGA functionals. These include dependence not only on $n(\mathbf{r})$ but also on its gradient $\nabla n(\mathbf{r})$. The general form is: \[ E_{\xc}^{\rm GGA}[n] = \int f\big(n(\mathbf{r}), \nabla n(\mathbf{r})\big)\, d^3r\,, \] where $f$ is some chosen function designed to satisfy known physical constraints. GGAs effectively recognize that the electron density varies in space and attempt to correct LDA by including gradient information (e.g., regions where density is rapidly changing like in molecular bonds or surfaces).
Popular GGA functionals: One prominent example is the Perdew–Burke–Ernzerhof (PBE) GGA (1996) which is a non-empirical functional built to satisfy certain exact constraints and known limits. Others include BLYP (Becke exchange + Lee-Yang-Parr correlation) which is popular in quantum chemistry, PW91 (an earlier Perdew–Wang 1991 GGA), etc. In GGA, the exchange energy density is modified from the LDA form by a factor depending on the gradient $ = |\nabla n|/(2k_F n)$ (reduced gradient), and similarly correlation gets a gradient correction.
Improvements with GGA: GGAs generally improve upon LDA for molecules and complex materials: 
Molecular bonds: GGA (like PBE or BLYP) typically gives better bond energies and lengths than LDA. For example, LDA’s overbinding is reduced; GGAs give bond lengths usually within 1$\%$ of experiment and correct the overbinding by a significant amount . Hydrogen bonds and weak interactions are still not perfect, but better than LDA .
Solids: GGA often over-corrects LDA’s tendencies: if LDA lattice constant was too small, GGA gives a slightly too large lattice constant. It’s observed that experimental lattice constants often lie between LDA (too low) and GGA (too high) . Bulk moduli are slightly underestimated in GGA (since the volume is larger).
Cohesive energies: GGA improves cohesive energy calculations for molecules and solids; LDA might overestimate cohesive energies (overbinding) while GGA brings them closer to experiment .

GGA limitations: 
They still miss long-range van der Waals forces (since those arise from non-local correlation, not captured by a semilocal functional). GGAs can err badly for systems like layered materials (graphite) or molecular crystals where dispersion is key.
They often still underestimate band gaps (though sometimes marginally better than LDA by a small amount).
Strongly correlated electron systems (e.g. Mott insulators, some transition metal oxides) are still poorly described (GGA often predicts them metallic unless an empirical $U$ correction is added).

Spin in LDA/GGA: In spin-polarized cases, one uses LSDA or GGA that are functions of $n_\uparrow, n_\downarrow$ (often constructed by applying LDA/GGA for each spin channel). This allows treatment of magnetism. For example, LSDA correctly predicts an exchange splitting in iron and a ferromagnetic ground state, though it may overestimate the magnetic moments slightly. 

!split
===== Beyond GGA: Meta-GGA and Hybrid Functionals =====

Meta-GGAs: These are functionals that include second derivatives or kinetic energy densities. For instance, a meta-GGA may use $n(\mathbf{r})$, $\nabla n$, and also the KS kinetic energy density $\tau(\mathbf{r}) = \sum_i \frac{\hbar^2}{2m}|\nabla \psi_i|^2$ or $\nabla^2 n$. Including $\tau$ helps the functional distinguish regions like bond versus slowly varying electron gas more effectively. An example is the SCAN functional (Strongly Constrained and Appropriately Normed, 2015) which is a meta-GGA that satisfies many known constraints and often achieves higher accuracy across diverse systems than typical GGA.
Hybrid functionals: These functionals mix a portion of exact exchange (from Hartree–Fock theory) with GGA exchange-correlation. The rationale is to mitigate the self-interaction error and correct the underestimated repulsion in LDA/GGA exchange. A general form: \[ E_{\xc}^{\rm hybrid} = E_{\xc}^{\rm GGA} + a \,(E_x^{\rm HF} - E_x^{\rm GGA})\,, \] where $E_x^{\rm HF}$ is the exact exchange energy from the KS orbitals (non-local), and $a$ is a mixing coefficient (commonly 20-2$5\%$). B3LYP is a famous hybrid in chemistry (with $a\approx 0.2$ plus some empirical parameters in correlation), and PBE0 is a hybrid with $a=0.25$ (25$\%$ exact exchange) based on PBE. Hybrids significantly improve molecular properties: they give much better reaction energy barriers, atomization energies, and often better equilibrium structures.
Why hybrids help: By adding exact exchange, hybrids correct the tendency of LDA/GGA to over-stabilize electron-rich regions. They also open up band gaps for insulators/semiconductors compared to LDA/GGA. For example, PBE (a GGA) predicts Si band gap ~0.6 eV while experiment is 1.1 eV; a hybrid like HSE (screened hybrid) or PBE0 might predict ~0.9–1.2 eV, much closer . In fact, the popular B3LYP functional was one reason DFT became widely used in quantum chemistry – it achieves “chemical accuracy” (~0.1 eV error) for many thermochemical properties  .
Cost of hybrids: The inclusion of exact exchange makes calculations more expensive (scaling roughly like Hartree–Fock, $O(N^4)$ with system size, rather than $O(N^3)$ for pure DFT). In extended systems (3D solids), exact exchange is particularly costly, though screened hybrids (like HSE06) make it more tractable by damping long-range exchange.
Empirical vs non-empirical: Some functionals (like B3LYP) had parameters fit to a training set of molecules, whereas PBE, SCAN, etc., are “non-empirical” (built from known physical constraints). Both approaches exist; empirical functionals can sometimes be very accurate for the types of systems they were fit to but might be less transferable.
Functional performance: Over the decades, improvement is incremental. For instance, GGA significantly improved over LDA by late 1980s ; hybrids in the 1990s improved further. Yet some problems remain challenging (van der Waals, strong correlation). Many newer functionals aim at specialized fixes (like DFT-D for dispersion, DFT+U for correlations – to be discussed below).



