\documentclass{beamer}
\usepackage[utf8]{inputenc}
\usepackage{physics}
\usepackage{hyperref}
\usepackage{xmpmulti}
\usepackage{braket}
\usepackage{tikz}
\usetheme{Madrid} % You can change the theme as you like
\usepackage{amsfonts,amssymb,stmaryrd,latexsym,amsmath,braket}
\usepackage{graphicx,subfigure}
\usepackage{comment}
\usepackage{times}
\usepackage{slashed}
\usepackage{bm}
\DeclareMathOperator{\sgn}{sgn}
\usecolortheme{seagull}


\begin{document}

\begin{frame}
\title[Quantum Computing and ML]{\textbf{Parametric matrix models}}
\author{Morten Hjorth-Jensen}
\institute{Department of Physics and Center for Computing in Science Education, University of Oslo, Norway}
\date{qGap Octover 7, 2025}
\titlepage
\end{frame}



\begin{frame}[plain,fragile]
\frametitle{Quantum control}

\begin{block}{The three steps of quantum control}
\begin{enumerate}
\item {\bf Quantum correlations:} Understanding and preparing an initial state
\item {\bf Quantum dynamics:} Controlled evolution towards a desired final state
\item {\bf Quantum measurements:} Measuring and characterizing the final state
\end{enumerate}


\end{block}

\end{frame}

\begin{frame}[plain,fragile]
\frametitle{Quantum control and this talk}

Last week we discussed the so-called Rodeo algorithm as a way to
prepare an initial state and/or find the eigenpairs of a system. This
week we will look at how to control the time-evolution of a system. In
so doing, we will study
\begin{block}{}
\begin{enumerate}
\item {\bf Quantum dynamics:} Controlled evolution towards a desired final state
  \begin{itemize}
  \item The Baker–Campbell–Hausdorff (BCH) formula
  \item Combining Exponentials of Non-commuting Operators and the Lie-Trotter formula (Trotterization)
  \item Parametric matrix models as a way to compute the Lie-Trotter formula, see \url{https://www.nature.com/articles/s41467-025-61362-4}, Cook, Jammooa, MHJ, Lee and Lee. See also \url{https://journals.aps.org/prxquantum/pdf/10.1103/1nqt-x5xh}
  \end{itemize}  
\end{enumerate}
\end{block}
\end{frame}



\begin{frame}{Motivation: Non-commuting Exponentials}
\begin{itemize}
\item In quantum mechanics and Lie theory, we often encounter operators $X$ and $Y$ that do not commute ($[X,Y] \neq 0$). Classic example is kinetic energy $\bm{K}$ and potential energy $\bm{V}$. Just think of the harmonic oscillator.
\item We want to find an effective operator $Z$ such that:
$e^{X} \, e^{Y} = e^{Z}$,
for $X,Y$ in a Lie algebra . If $X$ and $Y$ commute, then simply $Z=X+Y$. If not, $Z$ includes additional correction terms.
\item \textbf{BCH Formula:} $Z = \log(e^X e^Y)$ is given by an infinite series in $X, Y$ and their commutators. It provides a systematic expansion to combine exponentials of non-commuting operators .
\item \textbf{Use Cases:} Combines two small transformations into one. Fundamental in connecting Lie group multiplication with Lie algebra addition, time-evolution with split Hamiltonians, etc.
\end{itemize}
\end{frame}

\begin{frame}{Commutators and Lie Algebra}
\begin{itemize}
\item The \textbf{commutator} of two operators is $[X,Y] = XY - YX$. 
\item For a Lie algebra (common for operators in quantum mechanics), commutators of algebra elements remain in the algebra.
\item The BCH formula asserts $Z$ can be expressed entirely in terms of $X$, $Y$, and nested commutators like $[X,[X,Y]]$, $[Y,[X,Y]]$, etc. – no other independent products appear .
\item Notation: It’s useful to denote $\mathrm{ad}_X(Y) := [X,Y]$. Then nested commutators are iterated adjoint actions (e.g. $\mathrm{ad}_X^2(Y) = [X,[X,Y]]$, etc.).
\item Here we  will assume some familiarity with basic identities  such as the Jacobi identity: $[X,[Y,Z]] + [Y,[Z,X]] + [Z,[X,Y]] = 0$, which will simplify nested commutators.
\end{itemize}
\end{frame}

\section{The BCH Formula}
\begin{frame}{BCH Expansion: First Terms}
For $Z = \log(e^X e^Y)$, the expansion begins:
\begin{align*}
\begin{split} Z &= X + Y \\ &\quad+ \frac{1}{2}[X, Y] \\ &\quad+ \frac{1}{12}\big([X,[X,Y]] + [Y,[Y,X]]\big) \\ &\quad- \frac{1}{24}[Y,[X,[X,Y]]] + \cdots \end{split}
\end{align*}
\begin{itemize}
\item The series alternates between symmetric and antisymmetric nested commutators at higher orders.
\end{itemize}
\end{frame}


\section{The BCH Formula}
\begin{frame}{BCH Expansion: First Terms, part 2}
\begin{itemize}
\item All higher-order terms involve nested commutators of $X$ and $Y$ only. No ordinary products without commutators appear (ensuring $Z$ lies in the same Lie algebra).
\item The coefficients $1/2, 1/12, 1/24, \ldots$ are fixed numerical values (involving Bernoulli numbers for higher terms). These were first worked out explicitly by Dynkin (1947) in general .
\end{itemize}
\end{frame}



\begin{frame}{Series Characteristics}
\begin{itemize}
\item The BCH series is generally infinite. In most cases, there is \textbf{no closed-form finite expression} for $Z$ in terms of a finite number of terms .
\item Each increasing order introduces more deeply nested commutators. For example:
\begin{itemize}
\item 1st order: $X+Y$
\item 2nd order: $[X,Y]$
\item 3rd order: $[X,[X,Y]]$, $[Y,[X,Y]]$
\item 4th order: $[Y,[X,[X,Y]]]$, $[X,[Y,[Y,X]]]$, etc.
\end{itemize}
\item The number of independent commutator terms grows rapidly with order. (All such terms up to 6th order are listed in the literature, but it becomes cumbersome beyond a few orders.)
\item Fortunately, many practical scenarios require only the first few terms for approximation.
\item If $X$ and $Y$ are “small” (e.g. small matrices or small time-step in evolution), the series converges and truncating after a few terms can give a good approximation .
\end{itemize}
\end{frame}

\begin{frame}{Derivation: to first order)}
\begin{itemize}
\item \textbf{Method:} Compare power series of $e^X e^Y$ and $e^Z$ and solve for $Z$ order-by-order .
\item Expand both sides:
\[
e^X e^Y = I + X + Y + \frac{1}{2}(X^2 + XY + YX + Y^2) + \frac{1}{6}(X^3 + \cdots) + \cdots
\]
\[
e^Z = I + Z + \frac{1}{2}Z^2 + \frac{1}{6}Z^3 + \cdots
\]
where $Z = X + Y + A_2 + A_3 + \cdots$ (with $A_n$ = terms of order $n$ in $X,Y$).
\item \textbf{First order:} Match linear terms: $Z^{(1)} = X + Y$. So far $Z = X+Y$.
\end{itemize}
\end{frame}


\begin{frame}{Derivation: second order}

The $e^X e^Y$ expansion has $\frac{1}{2}(XY + YX)$ at order 2. Meanwhile $e^Z$ gives $\frac{1}{2}(X+Y)^2 = \frac{1}{2}(X^2 + XY + YX + Y^2)$. The extra $X^2$ and $Y^2$ terms match on both sides, but $XY+YX$ vs $XY+YX$ is already present. However, note that $XY + YX$ cannot simplify to $2XY$ unless $XY=YX$. The discrepancy appears at this order.


Thus, we postulate $Z$ has a second-order correction $A_2 = \frac{1}{2}[X,Y]$ to account for the difference:
\[  
XY + YX = (X+Y)^2 - X^2 - Y^2 = XY + YX,
\]
but including $A_2$ in $Z$ yields new cross terms when squaring $Z$:
\[
\frac{1}{2}(X+Y+A_2)^2 = \frac{1}{2}(X^2 + XY+YX + Y^2 + [X,Y]).
\]
which adds the $[X,Y]$ term we need. We have thus $A_2 = \frac{1}{2}[X,Y]$ .
\end{frame}



\begin{frame}{Derivation: third order}

\textbf{Third order:} Now include $A_2$ and match cubic terms. There will be terms involving $X^2Y$, $XY^2$, etc. The mismatch yields terms $[X,[X,Y]]$ and $[Y,[X,Y]]$. By similar (though more involved) analysis or using the Jacobi identity, one finds
\[
A_3 = \frac{1}{12}[X,[X,Y]] - \frac{1}{12}[Y,[X,Y]], 
\]
which is equivalent to
\[
\frac{1}{12}([X,[X,Y]] + [Y,[Y,X]]).
\]

This procedure can continue to higher orders (though it becomes increasingly complex).

\end{frame}


\begin{frame}{Special case: scalar multiple}

  \begin{itemize}
\item If $[X,Y] = c,I$, a scalar multiple of the identity, \textbf{all higher-order commutators vanish}. In this case the BCH series \emph{terminates} after the second term .
\item Then the exact result is:
\[  
Z = X + Y + \frac{1}{2}[X,Y],
\]
and no further corrections are needed.
\item This scenario occurs often in quantum mechanics when $[X,Y]$ is a c-number (for example, if $X$ and $Y$ are operators proportional to canonical variables $p$ and $q$).
\end{itemize}
\end{frame}


\begin{frame}{Special case: scalar multiple}

  \begin{itemize}
\item \textbf{Example:} Position and momentum operators satisfy $[x, p] = i\hbar I$. Thus,
\[  
e^{\frac{i}{\hbar} a x}\,e^{\frac{i}{\hbar} b p} = \exp\!\Big(\frac{i}{\hbar}(a x + b p) + \frac{i}{2\hbar} a b [x,p]\Big) = e^{\frac{i}{\hbar}(a x + b p + \frac{1}{2}ab\,i\hbar)},
\]
yielding a phase factor $e^{-i ab/2}$ times $e^{\frac{i}{\hbar}(a x + b p)}$.  (This is the basis of the Weyl representation in quantum mechanics.)
\item Another example: For harmonic oscillator ladder operators $[a, a^\dagger]=1$, the displacement operator factorization $e^{\alpha a} e^{-\alpha^* a^\dagger} = e^{-|\alpha|^2/2} e^{-\alpha^* a^\dagger + \alpha a}$ follows from BCH truncation.
\end{itemize}
\end{frame}


\section{Applications}
\begin{frame}{Application: Lie groups and Lie algebras}
\begin{itemize}
\item The BCH formula formalizes how group multiplication near the identity corresponds to addition in the Lie algebra plus commutator corrections .
\item If $X$ and $Y$ are infinitesimal generators (Lie algebra elements), $e^X$ and $e^Y$ are group elements. Their product $e^X e^Y$ can be expressed as $e^Z$ with $Z$ in the Lie algebra, ensuring closure of the group-law in algebra terms.
\item This underpins the Lie group–Lie algebra correspondence: the complicated group law (when the group is nonabelian) is captured by a formal power series in the algebra.
\end{itemize}
\end{frame}


\section{Applications}
\begin{frame}{Application: Lie groups and Lie algebras, example}
\begin{itemize}
\item \textbf{Example:} In $SO(3)$ (rotations), let $X$ and $Y$ be two small rotation generators (non-commuting). $e^X e^Y$ is a rotation whose generator $Z$ is given by BCH. Thus, the axis and angle of the combined rotation can be found by computing $Z$. (In practice, one can compute up to a certain order if $X, Y$ are small.)
\item The BCH formula is used to prove properties like $\operatorname{tr}(\log(e^X e^Y)) = \operatorname{tr}(X) + \operatorname{tr}(Y)$ (since commutator contributions have zero trace) , and other structural results in Lie theory.
\end{itemize}
\end{frame}


\begin{frame}{Application: quantum time evolution, dynamics part in quantum control}
\begin{itemize}
\item In quantum mechanics, if the Hamiltonian $H = H_1 + H_2$ (two parts that do not commute, like kinetic and potential energy), the time-evolution operator is $U(t) = e^{-i H t}$. Directly computing $e^{-i(H_1+H_2)t}$ is hard if $H_1$ and $H_2$ don’t commute.
\item Using BCH, we can approximate:
\[  
e^{-i(H_1+H_2)\Delta t} = \exp\Big(-i H_1 \Delta t - i H_2 \Delta t - \frac{1}{2}[H_1, H_2](\Delta t)^2 + \cdots \Big) ,
\]
so to first order in $\Delta t$,
\[
e^{-i(H_1+H_2)\Delta t} \approx e^{-iH_1 \Delta t} e^{-iH_2 \Delta t},
\]
with an error of order $(\Delta t)^2$ governed by $\frac{-i}{2}[H_1,H_2](\Delta t)^2$.
\end{itemize}
\end{frame}


\begin{frame}{Application: quantum time evolution, Trotterization}
\begin{itemize}
\item \textbf{Lie–Trotter Product Formula:} By taking $n$ small time steps,
\[  
\Big(e^{-iH_1 t/n} e^{-iH_2 t/n}\Big)^n = e^{-i(H_1+H_2)t + O(t^2/n)} \to e^{-i(H_1+H_2)t} \text{ as } n\to\infty .
\]
In practice, even modest $n$ yields a good approximation.
\item Higher-order splitting schemes (e.g. \textbf{Suzuki–Trotter decompositions}) use BCH terms cleverly to cancel lower-order errors. For example:
\[  
e^{-i(H_1+H_2)\Delta t} = e^{-iH_1 \Delta t/2} e^{-iH_2 \Delta t} e^{-iH_1 \Delta t/2} + O((\Delta t)^3) ,
\]
which eliminates the $O((\Delta t)^2)$ error by symmetry. BCH provides the systematic way to analyze these errors (they come from commutators $[H_1,H_2]$, $[H_1,[H_1,H_2]]$, etc.).
\item These formulas are widely used to simulate time evolution when $H_1$ and $H_2$ represent different parts (e.g. kinetic and potential energy in the quantum Hamiltonian) .
\end{itemize}
\end{frame}



\begin{frame}{Application: Quantum Computing (Hamiltonian Simulation)}
\begin{itemize}
\item In quantum algorithms, especially for Hamiltonian simulation such as diffusion Monte Carlo, we need to implement $U(t) = e^{-i(H_1+H_2+\cdots) t}$ via a sequence of quantum gates.
\item The BCH formula underlies the \textbf{Trotter-Suzuki product formula} approach:
\[  
e^{-i(H_1+H_2)t} \approx \left(e^{-iH_1 t/n} e^{-iH_2 t/n}\right)^n,
\]
which becomes exact as $n \to \infty$ . For finite $n$, one incurs a small error.
\item The leading error term is $\sim \frac{t^2}{2n}[H_1,H_2]$ from the BCH expansion . By increasing $n$ (more, smaller time slices), the error can be made arbitrarily small, at the cost of more gates.
\end{itemize}
\end{frame}


\begin{frame}{Application: Quantum Computing (Hamiltonian Simulation)}
\begin{itemize}
\item Quantum computing implementations often use higher-order BCH-based formulas to reduce error. For instance, the second-order formula above, or higher-order Suzuki expansions, include additional exponentials to cancel out commutator errors up to higher orders.
\item \textbf{Example:} To simulate $H = H_x + H_y + H_z$ (say parts of a Hamiltonian along $x,y,z$ axes), one can use:
\[  
U(t) \approx \big(e^{-iH_x t/m} e^{-iH_y t/m} e^{-iH_z t/m}\big)^m,
\]
and choose $m$ large. BCH tells us the error scales with nested commutators like $[H_x,[H_y,H_z]]$ and so on, often suppressed by $(t/m)^2$ or higher.
\item The BCH formula thus provides a quantitative handle on the gate complexity vs. accuracy trade-off in digital quantum simulations (a current research topic) .
\end{itemize}
\end{frame}

\section{Python Demonstrations}
\begin{frame}[fragile]{Symbolic Computation with Sympy}
Using \texttt{Sympy}, we can manipulate non-commuting symbols and verify the BCH expansion:
\begin{verbatim}
from sympy.physics.quantum import Commutator, Operator
from sympy import Rational, expand
X, Y = Operator('X'), Operator('Y')
# BCH series up to third order:  
Z =X+Y+Rational(1,2)*Commutator(X, Y)+ Rational(1,12)*(Commutator(X, Commutator(X,Y))+ Commutator(Y, Commutator(Y,X)))
print(Z.expand(commutator=True))
\end{verbatim}

This code constructs $Z = X+Y + \frac{1}{2}[X,Y] + \frac{1}{12}([X,[X,Y]]+[Y,[Y,X]])$ and then expands commutators. The output confirms:
\[
Z = X + Y + \frac{1}{2}[X,Y] + \frac{1}{12}([X,[X,Y]] - [B,[A,B]]),
\]
which, noting $[Y,[Y,X]] = -[Y,[X,Y]]$, matches the expected formula.
\end{frame}

\begin{frame}[fragile]{Numerical Vvrification with Numpy}
We can also numerically test how including commutator terms improves the approximation. Consider two small $2\times 2$ matrices $A$ and $B$:
\begin{verbatim}
import numpy as np
from numpy.linalg import norm
from scipy.linalg import expm  # matrix exponential
A = np.array([[0, 0.1],[0, 0   ]])
B = np.array([[0,   0 ],[0.1, 0 ]])

#Compute exponentials:
U = expm(A) @ expm(B)          # e^A e^B
U_direct = expm(A + B)         # e^{A+B}
U_BCH = expm(A + B + 0.5*(A@B - B@A))  # e^{A+B+0.5[A,B]}
print('(e^A e^B - e^{A+B}=)', norm(U - U_direct))
print('(e^A e^B - e^{A+B+0.5[A,B]}=)', norm(U - U_BCH))

\end{verbatim}
\end{frame}

\begin{frame}[fragile]{Numerical Verification with Numpy}
\textbf{Output:}\
{\footnotesize{}$\displaystyle ||e^A e^B - e^{A+B}|| = 7.07\times 10^{-3}, \qquad
||e^A e^B - e^{A+B+0.5[A,B]}|| = 2.38\times 10^{-4}.$}
\vspace{1ex}
Including the $[A,B]$ term in the exponent dramatically reduces the error (by about one order of magnitude in this example).
This illustrates how the BCH correction $\frac{1}{2}[A,B]$ captures the leading non-commutativity error.
\end{frame}



\begin{frame}{More on Quantum Hamiltonian evolution and Trotter-Suzuki}

\begin{block}{The time evolution operator for a quantum system is $U(t)=e^{-iHt}$}
Solving the Schrödinger equation $i,\frac{d}{dt}|\psi(t)\rangle =
H|\psi(t)\rangle$ . Simulating $U(t)$ is essential in physics and
chemistry.
\end{block}

\end{frame}


\begin{frame}{More on Quantum Hamiltonian evolution and Trotter-Suzuki}


\begin{block}{}
Many Hamiltonians are a sum of terms, $H=\sum_j H_j$ . If all terms
commute, time evolution factorizes exactly: e.g. for $H=H_1+H_2$ with
$[H_1,H_2]=0$, we have
\[
e^{-i(H_1+H_2)t}=e^{-iH_1 t}e^{-iH_2 t}.
\]
In general $H_j$ \textit{do not} commute, so
\[
e^{-i(H_1+H_2)t}\neq e^{-iH_1t}e^{-iH_2t}.
\]
We need to approximate the evolution by alternating the non-commuting pieces in small time slices. 
\end{block}
\end{frame}


\begin{frame}{Trotter Product Formula}
The standard Trotter-Suzuki decomposition (first-order splitting)
\[
e^{-i(H_1+H_2)t} = \lim_{N\to\infty}\Big(e^{-iH_1 \frac{t}{N}}\;e^{-iH_2 \frac{t}{N}}\Big)^N.
\]

In the infinite step limit, it becomes exact (also known as the Lie
product formula or Trotter formula ).  For finite $N$,
\[
(e^{-iH_1t/N}e^{-iH_2 t/N})^N,
\]
approximates $e^{-i(H_1+H_2)t}$ with some
error. Using a finite $N$ steps is called Trotterization, and the
approximation error can be bounded by a desired $\epsilon$. 

\end{frame}


\begin{frame}{Higher-order Trotter-Suzuki decompositions}

By symmetrizing the sequence, we can cancel lower-order errors. For example, a second-order formula uses half-step kicks of $H_1$: 
\[
S_{2}(\Delta) \;=\; e^{-iH_1 \Delta/2}\;e^{-iH_2 \Delta}\;e^{-iH_1 \Delta/2},
\]
which yields 
\[
e^{-i(H_1+H_2)\Delta},
\]
up to $O(\Delta^3)$ error. This symmetric Trotter-Suzuki formula eliminates the $O(\Delta^2)$ term.
In general, there are higher even-order formulas ($4$th, $6$th, …) that achieve errors $O(\Delta^{p+1})$ for any desired order $p$ . These higher-order decompositions (derived recursively by Suzuki) require more instances of the exponential operators (and sometimes negative-time coefficients) to cancel lower-order commutator errors. 

\end{frame}


\section{Detailed examples and derivations}

\begin{frame}{First-Order Trotter Expansion (Derivation)}
Using the Baker–Campbell–Hausdorff (BCH) formula, one finds:
\[
e^{A}e^{B} = \exp\!\Big(A + B + \tfrac{1}{2}[A,B] + \tfrac{1}{12}[A,[A,B]] - \tfrac{1}{12}[B,[A,B]] + \cdots\Big).
\]

For $A=-iH_1 \Delta,;B=-iH_2 \Delta$:
\[
e^{-iH_1 \Delta}e^{-iH_2 \Delta} = \exp\!\Big(-i(H_1+H_2)\Delta \;-\; \tfrac{1}{2}[H_1,H_2]\,\Delta^2 + O(\Delta^3)\Big).
\]

Thus, a single Trotter step incurs a local error term
$-\frac{1}{2}[H_1,H_2]\Delta^2$. The leading error scales as
$O(\Delta^2)$, so after $N=t/\Delta$ steps the total error is
$O(t,\Delta)$ (first order in $\Delta$).

\end{frame}

\begin{frame}{Second-order Trotter expansion (Insight)}

In the symmetric product
\[
S_2(\Delta)=e^{-iH_1\Delta/2}e^{-iH_2\Delta}e^{-iH_1\Delta/2},
\]
the first-order commutator terms cancel out. Intuitively, the $[H_1,H_2]$ error from the first half-step is negated by the second half-step.
The leading error in $S_2$ involves double commutators like $[H_1,[H_1,H_2]]$ (and $[H_2,[H_1,H_2]]$) , which enter at order $O(\Delta^3)$. Thus the second-order scheme has local error $O(\Delta^3)$ (global error $O(\Delta^2)$), a significant improvement over first order. 

\end{frame}


\begin{frame}{Example: Single-Qubit $H = X + Z$}

Consider a single qubit with Hamiltonian with Pauli $X$ and $Z$
\[
H = \sigma_X + \sigma_Z.
\]


Here $[X,Z] = 2iY \neq 0$.

We cannot implement $e^{-i(X+Z)t}$ as one gate, but must Trotterize.
Trotter strategy: alternate short rotations about the $X$-axis and $Z$-axis. For small $\Delta t$, $e^{-iX \Delta t}$ and $e^{-iZ \Delta t}$ are simpler rotations. Repeating them approximates the full evolution $e^{-i(X+Z)t}$ .
In this case, $e^{-iX \theta} = R_x(2\theta)$ and $e^{-iZ \theta} = R_z(2\theta)$, standard single-qubit rotations . Thus each Trotter step can be directly realized as two orthogonal axis rotations on the qubit. 

\end{frame}

\begin{frame}[fragile]{Trotterization in Python (First-Order)}

\begin{verbatim}
import numpy as np
from numpy.linalg import norm
from scipy.linalg import expm

#Define Pauli matrices
X = np.array([[0, 1],[1, 0]])
Z = np.array([[1, 0],[0,-1]])
H = X + Z
t = 1.0
N = 4
dt = t/N
#First-order Trotter approximation
U_trot = np.eye(2)
for k in range(N):
    U_trot = expm(-1j * X * dt) @ expm(-1j * Z * dt) @ U_trot
#Exact evolution
U_exact = expm(-1j * H * t)
error = norm(U_trot - U_exact)
print(error)
\end{verbatim}
\end{frame}


\begin{frame}{Results: Trotter approximation error}

With $N=4$ time steps, the first-order Trotter approximation gives
\[
|U_{\text{trot}} - U_{\text{exact}}| \approx 2.5\times10^{-1}.
\]


Increasing to $N=16$ steps reduces the error to $\sim6\times10^{-2}$. Doubling $N$ roughly halves the error, consistent with $O(1/N)$ convergence (global error $\sim O(t/N)$ for first order).
\end{frame}

\begin{frame}{Results: Trotter Approximation Error to 2nd order}

 A second-order Trotter scheme yields far smaller error for the same
$N$. For example, at $N=4$ steps, the symmetric formula gives error
$\sim2.4\times10^{-2}$ (about 10× smaller than first order). This
faster convergence (error $\sim O(1/N^2)$) is evident in practice.  In
general, each $e^{-iH_j \Delta t}$ corresponds to a quantum gate
implementing that term. In this 1-qubit example, $e^{-iX\Delta t}$ and
$e^{-iZ\Delta t}$ are rotations about $X$ and $Z$ axes. Thus the
Trotterized $e^{-i(X+Z)t}$ can be realized as a sequence of short
rotations, which becomes exact in the limit of fine steps . 


\end{frame}



\begin{frame}{Scaling of Trotter Steps with Accuracy}

The number of Trotter steps required grows as a function of the
simulation time $t$ and desired accuracy $\epsilon$: 

\begin{enumerate}
\item First order:
global error $\sim O(t^2/N)$, so to achieve error $\epsilon$ one needs
$N = O(t^2/\epsilon)$ steps (gate operations) .
\item Second order: global
error $\sim O(t^3/N^2)$, so one needs $N =
O!\big((t^3/\epsilon)^{1/2}\big) = O(t^{3/2}/\sqrt{\epsilon})$ steps
for error $\epsilon$.
\end{enumerate}

Higher-order Suzuki formulas further reduce the scaling. In practice,
there is a trade-off: higher order means more gates per step. One
chooses an order that minimizes total error (Trotter error + hardware
errors) for a given quantum hardware . 

\end{frame}




\end{document}







\end{document}

\section{Examples and Exercises}
\begin{frame}{Worked Example: SU(2) Rotations}
As an example in a physics context, consider spin-$\frac{1}{2}$ operators (Pauli matrices). Let $X = i \theta \sigma_x$ and $Y = i \phi \sigma_y$, which generate rotations about the $x$- and $y$-axes by angles $\theta$ and $\phi$.
\begin{itemize}
\item We know $[\sigma_x, \sigma_y] = 2i,\sigma_z$. Thus, $[X,Y] = i^2 \theta\phi [\sigma_x,\sigma_y] = -2 \theta \phi, \sigma_z$.
\item Since $\sigma_z$ does not commute with $\sigma_x$ or $\sigma_y$, higher commutators will appear (the algebra is nonabelian but finite-dimensional).
\item Using the BCH formula up to second order:
Z \approx X + Y + \frac{1}{2}[X,Y] = i\theta \sigma_x + i\phi \sigma_y - \theta\phi\,\sigma_z\,.
This suggests $e^X e^Y \approx \exp(i \theta \sigma_x + i \phi \sigma_y - \theta\phi,\sigma_z)$ for small angles.
\item In fact, the exact combined rotation $e^{i\theta \sigma_x} e^{i\phi \sigma_y}$ equals a rotation about some axis in the $xy$-plane (at third order one would find adjustments to the axis angle). The BCH series can be resummed in this case to give a closed-form result (via $\mathrm{SO}(3)$ formulas for combining rotations).
\item The key takeaway: BCH correctly identifies the $\sigma_z$ component (proportional to $[X,Y]$) in the resultant rotation generator.
\end{itemize}
\end{frame}

\begin{frame}{Exercises for Practice}
\begin{enumerate}
\item Derive the BCH formula up to the third order term explicitly:
\begin{enumerate}
\item Start from $\log(e^X e^Y) = Z = X+Y + A_2 + A_3 + \cdots$. Equate series coefficients to show $A_2 = \frac{1}{2}[X,Y]$ and $A_3 = \frac{1}{12}[X,[X,Y]] - \frac{1}{12}[Y,[X,Y]]$.
\item (\textit{Hint:} Use the expansion method or the identity $e^X Y e^{-X} = Y + [X,Y] + \frac{1}{2!}[X,[X,Y]] + \cdots$ to assist in the derivation.)
\end{enumerate}
\item For operators $A$ and $B$ such that $[A,B]=cI$ (a central commutator), prove that $e^A e^B = \exp(A+B + \frac{1}{2}[A,B])$ exactly. Verify this formula with a concrete example (e.g. $2\times2$ matrices or simple $2\times2$ block matrices).
\item Using the first-order Trotter approximation, show that
e^{(H_1+H_2)\Delta t} = e^{H_1 \Delta t} e^{H_2 \Delta t} + O((\Delta t)^2)\,,
and determine the form of the $O(\Delta t^2)$ error term using the BCH expansion. What commutator appears?
\item Consider two $2\times 2$ matrices (for example, Pauli matrices or random matrices) and numerically check the BCH formula:
\begin{enumerate}
\item Compute $Z_{\text{BCH}}^{(n)} = X + Y + \frac{1}{2}[X,Y] + \cdots$ up to $n$th order for your chosen $X, Y$.
\item Compare $e^X e^Y$ with $\exp(Z_{\text{BCH}}^{(n)})$ for increasing $n$ (e.g. using a Python script). How does the approximation improve as you include higher-order terms?
\end{enumerate}
\item (Challenge) Use the BCH formula to show the identity $e^X Y e^{-X} = Y + [X,Y] + \frac{1}{2!}[X,[X,Y]] + \frac{1}{3!}[X,[X,[X,Y]]] + \cdots$. (This is known as the Baker–Hausdorff lemma, a special case of BCH.) What simplifications occur if $[X,Y]$ commutes with $X$?
\end{enumerate}
\end{frame}

\begin{frame}{Summary}
\begin{itemize}
\item The Baker–Campbell–Hausdorff formula provides a powerful tool to combine exponentials of non-commuting operators into a single exponential. It expresses the result as an infinite series of nested commutators .
\item In general, the series is infinite and has no closed form, but truncations are extremely useful for approximate calculations .
\item The first few terms ($X+Y$, $\frac{1}{2}[X,Y]$, $\frac{1}{12}[X,[X,Y]]$, $\dots$) often give insight into how non-commutativity affects combined operations.
\item BCH is foundational in Lie theory (connecting local group structure to Lie algebra) and in practical computations in physics (quantum mechanics, quantum computing, optics, etc.) wherever splitting exponentials is needed .
\item Through examples and exercises, we saw how BCH explains the error in splitting methods and how it can be checked with symbolic or numeric computation.
\item Bottom line: Whenever you see $e^X e^Y$, remember the BCH formula allows you to rewrite it as $e^Z$ with $Z = X+Y + \frac{1}{2}[X,Y] + \cdots$. This not only simplifies theoretical manipulations but also guides practical approximations in computations.
\end{itemize}
\end{frame}








%
\section{Exercises}

\begin{frame}{Exercises}
\begin{enumerate}
\item Use the BCH expansion to show the leading correction term for $U_{\text{trot}}(\Delta) = e^{-iH_1\Delta}e^{-iH_2\Delta}$ is $-\tfrac{i}{2}[H_1,H_2]\Delta^2$.  (Hint: Expand $e^{-iH_1\Delta}e^{-iH_2\Delta}$ to second order in $\Delta$.)
\item Verify that in the second-order formula $S_2(\Delta)=e^{-iH_1\Delta/2}e^{-iH_2\Delta}e^{-iH_1\Delta/2}$, the $[H_1,H_2]$ term cancels out. What commutator(s) govern the leading error term of $S_2$?
\item Write a Python script (using NumPy) to simulate $U(t)=e^{-iHt}$ for a simple $2\times2$ Hamiltonian $H=H_1+H_2$ with and without Trotterization. Compare the norm error $|U_{\text{trot}} - U|$ for different $N$ and for first vs second-order Trotterization.
\end{enumerate}
\end{frame}

\end{document}








 









