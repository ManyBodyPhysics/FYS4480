
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>14. Optimization and Vectorization &#8212; Quantum Mechanics for Many-Particle Systems; from standard methods to quantum computing and machine learning</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!-- 
    this give us a css class that will be invisible only if js is disabled 
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=26a4bc78f4c0ddb94549" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=26a4bc78f4c0ddb94549" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- So that users can add custom icons -->
  <script src="_static/scripts/fontawesome.js?digest=26a4bc78f4c0ddb94549"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=26a4bc78f4c0ddb94549" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=26a4bc78f4c0ddb94549" />

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=36754332"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'vectorization';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="15. Parallelization with MPI and OpenMPI" href="parallelization.html" />
    <link rel="prev" title="13. Boltzmann Machines" href="boltzmannmachines.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="Quantum Mechanics for Many-Particle Systems; from standard methods to quantum computing and machine learning - Home"/>
    <img src="_static/logo.png" class="logo__image only-dark pst-js-only" alt="Quantum Mechanics for Many-Particle Systems; from standard methods to quantum computing and machine learning - Home"/>
  
  
</a></div>
        <div class="sidebar-primary-item">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Quantum mechanics for many-particle systems
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">About the course</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="schedule.html">Schedule</a></li>
<li class="toctree-l1"><a class="reference internal" href="teachers.html">Instructor information</a></li>
<li class="toctree-l1"><a class="reference internal" href="textbooks.html">Textbooks</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Basics of Many-Body Physics</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="notation.html">1. Introduction to many-body physics</a></li>
<li class="toctree-l1"><a class="reference internal" href="secondquant.html">2. Introduction to  second quantization</a></li>
<li class="toctree-l1"><a class="reference internal" href="fci.html">3. Full configuration interaction theory</a></li>
<li class="toctree-l1"><a class="reference internal" href="hfock.html">4. Hartree-Fock theory</a></li>

</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Post Hartree-Fock Methods</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="mbpt.html">6. Many-body perturbation theory</a></li>
<li class="toctree-l1"><a class="reference internal" href="cc.html">7. The Coupled Cluster Method</a></li>


</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Stochastic Methods</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="vmcdmc.html">10. Variational Monte Carlo methods</a></li>
<li class="toctree-l1"><a class="reference internal" href="gradientmethods.html">11. Gradient Methods</a></li>
<li class="toctree-l1"><a class="reference internal" href="resamplingmethods.html">12. Resampling Techniques, Bootstrap and Blocking</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Deep Learning methods</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="boltzmannmachines.html">13. Boltzmann Machines</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Computational Aspects</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 current active"><a class="current reference internal" href="#">14. Optimization and Vectorization</a></li>
<li class="toctree-l1"><a class="reference internal" href="parallelization.html">15. Parallelization with MPI and OpenMPI</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://mybinder.org/v2/gh/executablebooks/jupyter-book/master?urlpath=tree/vectorization.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch on Binder"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img alt="Binder logo" src="_static/images/logo_binder.svg">
  </span>
<span class="btn__text-container">Binder</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/vectorization.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button>


<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Optimization and Vectorization</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#optimization-and-profiling">14.1. Optimization and profiling</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#more-on-optimization">14.2. More on optimization</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">14.3. Optimization and profiling</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#optimization-and-debugging">14.4. Optimization and debugging</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#other-hints">14.5. Other hints</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#vectorization-and-the-basic-idea-behind-parallel-computing">14.6. Vectorization and the basic idea behind parallel computing</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#a-rough-classification-of-hardware-models">14.7. A rough classification of hardware models</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#shared-memory-and-distributed-memory">14.8. Shared memory and distributed memory</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#different-parallel-programming-paradigms">14.9. Different parallel programming paradigms</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">14.10. Different parallel programming paradigms</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-is-vectorization">14.11. What is vectorization?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#number-of-elements-that-can-acted-upon">14.12. Number of elements that can acted upon</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#number-of-elements-that-can-acted-upon-examples">14.13. Number of elements that can acted upon, examples</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#operation-counts-for-scalar-operation">14.14. Operation counts for scalar operation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">14.15. Number of elements that can acted upon, examples</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#number-of-operations-when-vectorized">14.16. Number of operations when vectorized</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#a-simple-test-case-with-and-without-vectorization">14.17. A simple test case with and without vectorization</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#compiling-with-and-without-vectorization">14.18. Compiling with and without vectorization</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#compiling-with-and-without-vectorization-using-clang">14.19. Compiling with and without vectorization using clang</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#automatic-vectorization-and-vectorization-inhibitors-criteria">14.20. Automatic vectorization and vectorization inhibitors, criteria</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#automatic-vectorization-and-vectorization-inhibitors-exit-criteria">14.21. Automatic vectorization and vectorization inhibitors, exit criteria</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#automatic-vectorization-and-vectorization-inhibitors-straight-line-code">14.22. Automatic vectorization and vectorization inhibitors, straight-line code</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#automatic-vectorization-and-vectorization-inhibitors-nested-loops">14.23. Automatic vectorization and vectorization inhibitors, nested loops</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#automatic-vectorization-and-vectorization-inhibitors-function-calls">14.24. Automatic vectorization and vectorization inhibitors, function calls</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#automatic-vectorization-and-vectorization-inhibitors-data-dependencies">14.25. Automatic vectorization and vectorization inhibitors, data dependencies</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#automatic-vectorization-and-vectorization-inhibitors-more-data-dependencies">14.26. Automatic vectorization and vectorization inhibitors, more data dependencies</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#automatic-vectorization-and-vectorization-inhibitors-memory-stride">14.27. Automatic vectorization and vectorization inhibitors, memory stride</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#memory-management">14.28. Memory management</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#memory-and-communication">14.29. Memory and communication</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#measuring-performance">14.30. Measuring performance</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#problems-with-measuring-time">14.31. Problems with measuring time</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#problems-with-cold-start">14.32. Problems with cold start</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#problems-with-smart-compilers">14.33. Problems with smart compilers</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#problems-with-interference">14.34. Problems with interference</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#problems-with-measuring-performance">14.35. Problems with measuring performance</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#thomas-algorithm-for-tridiagonal-linear-algebra-equations">14.36. Thomas algorithm for tridiagonal linear algebra equations</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#thomas-algorithm-forward-substitution">14.37. Thomas algorithm, forward substitution</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#thomas-algorithm-backward-substitution">14.38. Thomas algorithm, backward substitution</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#thomas-algorithm-and-counting-of-operations-floating-point-and-memory">14.39. Thomas algorithm and counting of operations (floating point and memory)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#example-transpose-of-a-matrix">14.40. Example: Transpose of a matrix</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#matrix-matrix-multiplication">14.41. Matrix-matrix multiplication</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-do-we-define-speedup-simplest-form">14.42. How do we define speedup? Simplest form</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-do-we-define-speedup-correct-baseline">14.43. How do we define speedup? Correct baseline</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#parallel-speedup">14.44. Parallel  speedup</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#speedup-and-memory">14.45. Speedup and memory</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#upper-bounds-on-speedup">14.46. Upper bounds on speedup</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#amdahl-s-law">14.47. Amdahl’s law</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="optimization-and-vectorization">
<h1><span class="section-number">14. </span>Optimization and Vectorization<a class="headerlink" href="#optimization-and-vectorization" title="Link to this heading">#</a></h1>
<section id="optimization-and-profiling">
<h2><span class="section-number">14.1. </span>Optimization and profiling<a class="headerlink" href="#optimization-and-profiling" title="Link to this heading">#</a></h2>
<p>Till now we have not paid much attention to speed and possible optimization possibilities
inherent in the various compilers. We have compiled and linked as</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>    c++  -c  mycode.cpp
    c++  -o  mycode.exe  mycode.o
</pre></div>
</div>
<p>For Fortran replace with for example <strong>gfortran</strong> or <strong>ifort</strong>.
This is what we call a flat compiler option and should be used when we develop the code.
It produces normally a very large and slow code when translated to machine instructions.
We use this option for debugging and for establishing the correct program output because
every operation is done precisely as the user specified it.</p>
<p>It is instructive to look up the compiler manual for further instructions by writing</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>    man c++
</pre></div>
</div>
</section>
<section id="more-on-optimization">
<h2><span class="section-number">14.2. </span>More on optimization<a class="headerlink" href="#more-on-optimization" title="Link to this heading">#</a></h2>
<p>We have additional compiler options for optimization. These may include procedure inlining where
performance may be improved, moving constants inside loops outside the loop,
identify potential parallelism, include automatic vectorization or replace a division with a reciprocal
and a multiplication if this speeds up the code.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>    c++  -O3 -c  mycode.cpp
    c++  -O3 -o  mycode.exe  mycode.o
</pre></div>
</div>
<p>This (other options are -O2 or -Ofast) is the recommended option.</p>
</section>
<section id="id1">
<h2><span class="section-number">14.3. </span>Optimization and profiling<a class="headerlink" href="#id1" title="Link to this heading">#</a></h2>
<p>It is also useful to profile your program under the development stage.
You would then compile with</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>    c++  -pg -O3 -c  mycode.cpp
    c++  -pg -O3 -o  mycode.exe  mycode.o
</pre></div>
</div>
<p>After you have run the code you can obtain the profiling information via</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>    gprof mycode.exe &gt;  ProfileOutput
</pre></div>
</div>
<p>When you have profiled properly your code, you must take out this option as it
slows down performance.
For memory tests use <a class="reference external" href="http://www.valgrind.org">valgrind</a>. An excellent environment for all these aspects, and much  more, is  Qt creator.</p>
</section>
<section id="optimization-and-debugging">
<h2><span class="section-number">14.4. </span>Optimization and debugging<a class="headerlink" href="#optimization-and-debugging" title="Link to this heading">#</a></h2>
<p>Adding debugging options is a very useful alternative under the development stage of a program.
You would then compile with</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>    c++  -g -O0 -c  mycode.cpp
    c++  -g -O0 -o  mycode.exe  mycode.o
</pre></div>
</div>
<p>This option generates debugging information allowing you to trace for example if an array is properly allocated. Some compilers work best with the no optimization option <strong>-O0</strong>.</p>
<p><strong>Other optimization flags.</strong></p>
<p>Depending on the compiler, one can add flags which generate code that catches integer overflow errors.
The flag <strong>-ftrapv</strong> does this for the CLANG compiler on OS X operating systems.</p>
</section>
<section id="other-hints">
<h2><span class="section-number">14.5. </span>Other hints<a class="headerlink" href="#other-hints" title="Link to this heading">#</a></h2>
<p>In general, irrespective of compiler options, it is useful to</p>
<ul class="simple">
<li><p>avoid if tests or call to functions inside loops, if possible.</p></li>
<li><p>avoid multiplication with constants inside loops if possible</p></li>
</ul>
<p>Here is an example of a part of a program where specific operations lead to a slower code</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>    k = n-1;
    for (i = 0; i &lt; n; i++){
        a[i] = b[i] +c*d;
        e = g[k];
    }
</pre></div>
</div>
<p>A better code is</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>    temp = c*d;
    for (i = 0; i &lt; n; i++){
        a[i] = b[i] + temp;
    }
    e = g[n-1];
</pre></div>
</div>
<p>Here we avoid a repeated multiplication inside a loop.
Most compilers, depending on compiler flags, identify and optimize such bottlenecks on their own, without requiring any particular action by the programmer. However, it is always useful to single out and avoid code examples like the first one discussed here.</p>
</section>
<section id="vectorization-and-the-basic-idea-behind-parallel-computing">
<h2><span class="section-number">14.6. </span>Vectorization and the basic idea behind parallel computing<a class="headerlink" href="#vectorization-and-the-basic-idea-behind-parallel-computing" title="Link to this heading">#</a></h2>
<p>Present CPUs are highly parallel processors with varying levels of parallelism. The typical situation can be described via the following three statements.</p>
<ul class="simple">
<li><p>Pursuit of shorter computation time and larger simulation size gives rise to parallel computing.</p></li>
<li><p>Multiple processors are involved to solve a global problem.</p></li>
<li><p>The essence is to divide the entire computation evenly among collaborative processors.  Divide and conquer.</p></li>
</ul>
<p>Before we proceed with a more detailed discussion of topics like vectorization and parallelization, we need to remind ourselves about some basic features of different hardware models.</p>
</section>
<section id="a-rough-classification-of-hardware-models">
<h2><span class="section-number">14.7. </span>A rough classification of hardware models<a class="headerlink" href="#a-rough-classification-of-hardware-models" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Conventional single-processor computers are named SISD (single-instruction-single-data) machines.</p></li>
<li><p>SIMD (single-instruction-multiple-data) machines incorporate the idea of parallel processing, using a large number of processing units to execute the same instruction on different data.</p></li>
<li><p>Modern parallel computers are so-called MIMD (multiple-instruction-multiple-data) machines and can execute different instruction streams in parallel on different data.</p></li>
</ul>
</section>
<section id="shared-memory-and-distributed-memory">
<h2><span class="section-number">14.8. </span>Shared memory and distributed memory<a class="headerlink" href="#shared-memory-and-distributed-memory" title="Link to this heading">#</a></h2>
<p>One way of categorizing modern parallel computers is to look at the memory configuration.</p>
<ul class="simple">
<li><p>In shared memory systems the CPUs share the same address space. Any CPU can access any data in the global memory.</p></li>
<li><p>In distributed memory systems each CPU has its own memory.</p></li>
</ul>
<p>The CPUs are connected by some network and may exchange messages.</p>
</section>
<section id="different-parallel-programming-paradigms">
<h2><span class="section-number">14.9. </span>Different parallel programming paradigms<a class="headerlink" href="#different-parallel-programming-paradigms" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p><strong>Task parallelism</strong>:  the work of a global problem can be divided into a number of independent tasks, which rarely need to synchronize.  Monte Carlo simulations represent a typical situation. Integration is another. However this paradigm is of limited use.</p></li>
<li><p><strong>Data parallelism</strong>:  use of multiple threads (e.g. one or more threads per processor) to dissect loops over arrays etc.  Communication and synchronization between processors are often hidden, thus easy to program. However, the user surrenders much control to a specialized compiler. Examples of data parallelism are compiler-based parallelization and OpenMP directives.</p></li>
</ul>
</section>
<section id="id2">
<h2><span class="section-number">14.10. </span>Different parallel programming paradigms<a class="headerlink" href="#id2" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p><strong>Message passing</strong>:  all involved processors have an independent memory address space. The user is responsible for  partitioning the data/work of a global problem and distributing the  subproblems to the processors. Collaboration between processors is achieved by explicit message passing, which is used for data transfer plus synchronization.</p></li>
<li><p>This paradigm is the most general one where the user has full control. Better parallel efficiency is usually achieved by explicit message passing. However, message-passing programming is more difficult.</p></li>
</ul>
</section>
<section id="what-is-vectorization">
<h2><span class="section-number">14.11. </span>What is vectorization?<a class="headerlink" href="#what-is-vectorization" title="Link to this heading">#</a></h2>
<p>Vectorization is a special
case of <strong>Single Instructions Multiple Data</strong> (SIMD) to denote a single
instruction stream capable of operating on multiple data elements in
parallel.
We can think of vectorization as the unrolling of loops accompanied with SIMD instructions.</p>
<p>Vectorization is the process of converting an algorithm that performs scalar operations
(typically one operation at the time) to vector operations where a single operation can refer to many simultaneous operations.
Consider the following example</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>    for (i = 0; i &lt; n; i++){
        a[i] = b[i] + c[i];
    }
</pre></div>
</div>
<p>If the code is not vectorized, the compiler will simply start with the first element and
then perform subsequent additions operating on one address in memory at the time.</p>
</section>
<section id="number-of-elements-that-can-acted-upon">
<h2><span class="section-number">14.12. </span>Number of elements that can acted upon<a class="headerlink" href="#number-of-elements-that-can-acted-upon" title="Link to this heading">#</a></h2>
<p>A SIMD instruction can operate  on multiple data elements in one single instruction.
It uses the so-called 128-bit SIMD floating-point register.
In this sense, vectorization adds some form of parallelism since one instruction is applied<br />
to many parts of say a vector.</p>
<p>The number of elements which can be operated on in parallel
range from four single-precision floating point data elements in so-called
Streaming SIMD Extensions and two double-precision floating-point data
elements in Streaming SIMD Extensions 2 to sixteen byte operations in
a 128-bit register in Streaming SIMD Extensions 2. Thus, vector-length
ranges from 2 to 16, depending on the instruction extensions used and
on the data type.</p>
<p>IN summary, our instructions  operate on 128 bit (16 byte) operands</p>
<ul class="simple">
<li><p>4 floats or ints</p></li>
<li><p>2 doubles</p></li>
<li><p>Data paths 128 bits vide for vector unit</p></li>
</ul>
</section>
<section id="number-of-elements-that-can-acted-upon-examples">
<h2><span class="section-number">14.13. </span>Number of elements that can acted upon, examples<a class="headerlink" href="#number-of-elements-that-can-acted-upon-examples" title="Link to this heading">#</a></h2>
<p>We start with the simple scalar operations given by</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>    for (i = 0; i &lt; n; i++){
        a[i] = b[i] + c[i];
    }
</pre></div>
</div>
<p>If the code is not vectorized  and we have a 128-bit register to store a 32 bits floating point number,
it means that we have <span class="math notranslate nohighlight">\(3\times 32\)</span> bits that are not used. For the first element we have</p>
<table border="1">
<thead>
<tr><th align="center">  0  </th> <th align="center">   1    </th> <th align="center">   2    </th> <th align="center">   3    </th> </tr>
</thead>
<tbody>
<tr><td align="center">   a[0]=    </td> <td align="center">   not used    </td> <td align="center">   not used    </td> <td align="center">   not used    </td> </tr>
<tr><td align="center">   b[0]+    </td> <td align="center">   not used    </td> <td align="center">   not used    </td> <td align="center">   not used    </td> </tr>
<tr><td align="center">   c[0]     </td> <td align="center">   not used    </td> <td align="center">   not used    </td> <td align="center">   not used    </td> </tr>
</tbody>
</table>
We have thus unused space in our SIMD registers. These registers could hold three additional integers.
</section>
<section id="operation-counts-for-scalar-operation">
<h2><span class="section-number">14.14. </span>Operation counts for scalar operation<a class="headerlink" href="#operation-counts-for-scalar-operation" title="Link to this heading">#</a></h2>
<p>The code</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>    for (i = 0; i &lt; n; i++){
        a[i] = b[i] + c[i];
    }
</pre></div>
</div>
<p>has for <span class="math notranslate nohighlight">\(n\)</span> repeats</p>
<ol class="arabic simple">
<li><p>one load for <span class="math notranslate nohighlight">\(c[i]\)</span> in address 1</p></li>
<li><p>one load for <span class="math notranslate nohighlight">\(b[i]\)</span> in address 2</p></li>
<li><p>add <span class="math notranslate nohighlight">\(c[i]\)</span> and <span class="math notranslate nohighlight">\(b[i]\)</span> to give <span class="math notranslate nohighlight">\(a[i]\)</span></p></li>
<li><p>store <span class="math notranslate nohighlight">\(a[i]\)</span> in address 2</p></li>
</ol>
</section>
<section id="id3">
<h2><span class="section-number">14.15. </span>Number of elements that can acted upon, examples<a class="headerlink" href="#id3" title="Link to this heading">#</a></h2>
<p>If we vectorize the code, we can perform, with a 128-bit register four simultaneous operations, that is
we have</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>    for (i = 0; i &lt; n; i+=4){
        a[i] = b[i] + c[i];
        a[i+1] = b[i+1] + c[i+1];
        a[i+2] = b[i+2] + c[i+2];
        a[i+3] = b[i+3] + c[i+3];
    }
</pre></div>
</div>
<p>displayed here as</p>
<table border="1">
<thead>
<tr><th align="center">  0  </th> <th align="center">  1  </th> <th align="center">  2  </th> <th align="center">  3  </th> </tr>
</thead>
<tbody>
<tr><td align="center">   a[0]=    </td> <td align="center">   a[1]=    </td> <td align="center">   a[2]=    </td> <td align="center">   a[3]=    </td> </tr>
<tr><td align="center">   b[0]+    </td> <td align="center">   b[1]+    </td> <td align="center">   b[2]+    </td> <td align="center">   b[3]+    </td> </tr>
<tr><td align="center">   c[0]     </td> <td align="center">   c[1]     </td> <td align="center">   c[2]     </td> <td align="center">   c[3]     </td> </tr>
</tbody>
</table>
Four additions are now done in a single step.
</section>
<section id="number-of-operations-when-vectorized">
<h2><span class="section-number">14.16. </span>Number of operations when vectorized<a class="headerlink" href="#number-of-operations-when-vectorized" title="Link to this heading">#</a></h2>
<p>For <span class="math notranslate nohighlight">\(n/4\)</span> repeats assuming floats or integers</p>
<ol class="arabic simple">
<li><p>one vector load for <span class="math notranslate nohighlight">\(c[i]\)</span> in address 1</p></li>
<li><p>one load for <span class="math notranslate nohighlight">\(b[i]\)</span> in address 2</p></li>
<li><p>add <span class="math notranslate nohighlight">\(c[i]\)</span> and <span class="math notranslate nohighlight">\(b[i]\)</span> to give <span class="math notranslate nohighlight">\(a[i]\)</span></p></li>
<li><p>store <span class="math notranslate nohighlight">\(a[i]\)</span> in address 2</p></li>
</ol>
</section>
<section id="a-simple-test-case-with-and-without-vectorization">
<h2><span class="section-number">14.17. </span><a class="reference external" href="https://github.com/CompPhysics/ComputationalPhysicsMSU/blob/master/doc/Programs/LecturePrograms/programs/Classes/cpp/program7.cpp">A simple test case with and without vectorization</a><a class="headerlink" href="#a-simple-test-case-with-and-without-vectorization" title="Link to this heading">#</a></h2>
<p>We implement these operations in a simple c++ program that computes at the end the norm of a vector.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>    #include &lt;cstdlib&gt;
    #include &lt;iostream&gt;
    #include &lt;cmath&gt;
    #include &lt;iomanip&gt;
    #include &quot;time.h&quot;
    
    using namespace std; // note use of namespace
    int main (int argc, char* argv[])
    {
      // read in dimension of square matrix
      int n = atoi(argv[1]);
      double s = 1.0/sqrt( (double) n);
      double *a, *b, *c;
      // Start timing
      clock_t start, finish;
      start = clock();
    // Allocate space for the vectors to be used
        a = new double [n]; b = new double [n]; c = new double [n];
      // Define parallel region
      // Set up values for vectors  a and b
      for (int i = 0; i &lt; n; i++){
        double angle = 2.0*M_PI*i/ (( double ) n);
        a[i] = s*(sin(angle) + cos(angle));
        b[i] =  s*sin(2.0*angle);
        c[i] = 0.0;
      }
      // Then perform the vector addition
      for (int i = 0; i &lt; n; i++){
        c[i] += a[i]+b[i];
      }
      // Compute now the norm-2
      double Norm2 = 0.0;
      for (int i = 0; i &lt; n; i++){
        Norm2  += c[i]*c[i];
      }
      finish = clock();
      double timeused = (double) (finish - start)/(CLOCKS_PER_SEC );
      cout &lt;&lt; setiosflags(ios::showpoint | ios::uppercase);
      cout &lt;&lt; setprecision(10) &lt;&lt; setw(20) &lt;&lt; &quot;Time used  for norm computation=&quot; &lt;&lt; timeused  &lt;&lt; endl;
      cout &lt;&lt; &quot;  Norm-2  = &quot; &lt;&lt; Norm2 &lt;&lt; endl;
      // Free up space
      delete[] a;
      delete[] b;
      delete[] c;
      return 0;
    }
</pre></div>
</div>
</section>
<section id="compiling-with-and-without-vectorization">
<h2><span class="section-number">14.18. </span>Compiling with and without vectorization<a class="headerlink" href="#compiling-with-and-without-vectorization" title="Link to this heading">#</a></h2>
<p>We can compile and link without vectorization using the clang c++ compiler</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>    clang -o novec.x vecexample.cpp
</pre></div>
</div>
<p>and with vectorization (and additional optimizations)</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>    clang++ -O3 -Rpass=loop-vectorize -o  vec.x vecexample.cpp 
</pre></div>
</div>
<p>The speedup depends on the size of the vectors. In the example here we have run with <span class="math notranslate nohighlight">\(10^7\)</span> elements.
The example here was run on an IMac17.1 with OSX El Capitan (10.11.4) as operating system and an Intel i5 3.3 GHz CPU.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>    Compphys:~ hjensen$ ./vec.x 10000000
    Time used  for norm computation=0.04720500000
    Compphys:~ hjensen$ ./novec.x 10000000
    Time used  for norm computation=0.03311700000
</pre></div>
</div>
<p>This particular C++ compiler speeds up the above loop operations with a factor of 1.5
Performing the same operations for <span class="math notranslate nohighlight">\(10^9\)</span> elements results in a smaller speedup since reading from main memory is required. The non-vectorized code is seemingly faster.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>    Compphys:~ hjensen$ ./vec.x 1000000000
    Time used  for norm computation=58.41391100
    Compphys:~ hjensen$ ./novec.x 1000000000
    Time used  for norm computation=46.51295300
</pre></div>
</div>
<p>We will discuss these issues further in the next slides.</p>
</section>
<section id="compiling-with-and-without-vectorization-using-clang">
<h2><span class="section-number">14.19. </span>Compiling with and without vectorization using clang<a class="headerlink" href="#compiling-with-and-without-vectorization-using-clang" title="Link to this heading">#</a></h2>
<p>We can compile and link without vectorization with clang compiler</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>    clang++ -o -fno-vectorize novec.x vecexample.cpp
</pre></div>
</div>
<p>and with vectorization</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>    clang++ -O3 -Rpass=loop-vectorize -o  vec.x vecexample.cpp 
</pre></div>
</div>
<p>We can also add vectorization analysis, see for example</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>    clang++ -O3 -Rpass-analysis=loop-vectorize -o  vec.x vecexample.cpp 
</pre></div>
</div>
<p>or figure out if vectorization was missed</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>    clang++ -O3 -Rpass-missed=loop-vectorize -o  vec.x vecexample.cpp 
</pre></div>
</div>
</section>
<section id="automatic-vectorization-and-vectorization-inhibitors-criteria">
<h2><span class="section-number">14.20. </span>Automatic vectorization and vectorization inhibitors, criteria<a class="headerlink" href="#automatic-vectorization-and-vectorization-inhibitors-criteria" title="Link to this heading">#</a></h2>
<p>Not all loops can be vectorized, as discussed in <a class="reference external" href="https://software.intel.com/en-us/articles/a-guide-to-auto-vectorization-with-intel-c-compilers">Intel’s guide to vectorization</a></p>
<p>An important criteria is that the loop counter <span class="math notranslate nohighlight">\(n\)</span> is known at the entry of the loop.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>      for (int j = 0; j &lt; n; j++) {
        a[j] = cos(j*1.0);
      }
</pre></div>
</div>
<p>The variable <span class="math notranslate nohighlight">\(n\)</span> does need to be known at compile time. However, this variable must stay the same for the entire duration of the loop. It implies that an exit statement inside the loop cannot be data dependent.</p>
</section>
<section id="automatic-vectorization-and-vectorization-inhibitors-exit-criteria">
<h2><span class="section-number">14.21. </span>Automatic vectorization and vectorization inhibitors, exit criteria<a class="headerlink" href="#automatic-vectorization-and-vectorization-inhibitors-exit-criteria" title="Link to this heading">#</a></h2>
<p>An exit statement should in general be avoided.
If the exit statement contains data-dependent conditions, the loop cannot be vectorized.
The following is an example of a non-vectorizable loop</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>      for (int j = 0; j &lt; n; j++) {
        a[j] = cos(j*1.0);
        if (a[j] &lt; 0 ) break;
      }
</pre></div>
</div>
<p>Avoid loop termination conditions and opt for a single entry loop variable <span class="math notranslate nohighlight">\(n\)</span>. The lower and upper bounds have to be kept fixed within the loop.</p>
</section>
<section id="automatic-vectorization-and-vectorization-inhibitors-straight-line-code">
<h2><span class="section-number">14.22. </span>Automatic vectorization and vectorization inhibitors, straight-line code<a class="headerlink" href="#automatic-vectorization-and-vectorization-inhibitors-straight-line-code" title="Link to this heading">#</a></h2>
<p>SIMD instructions perform the same type of operations multiple times.
A <strong>switch</strong> statement leads thus to a non-vectorizable loop since different statemens cannot branch.
The following code can however be vectorized since the <strong>if</strong> statement is implemented as a masked assignment.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>      for (int j = 0; j &lt; n; j++) {
        double x  = cos(j*1.0);
        if (x &gt; 0 ) {
           a[j] =  x*sin(j*2.0); 
        }
        else {
           a[j] = 0.0;
        }
      }
</pre></div>
</div>
<p>These operations can be performed for all data elements but only those elements which the mask evaluates as true are stored. In general, one should avoid branches such as <strong>switch</strong>, <strong>go to</strong>, or <strong>return</strong> statements or <strong>if</strong> constructs that cannot be treated as masked assignments.</p>
</section>
<section id="automatic-vectorization-and-vectorization-inhibitors-nested-loops">
<h2><span class="section-number">14.23. </span>Automatic vectorization and vectorization inhibitors, nested loops<a class="headerlink" href="#automatic-vectorization-and-vectorization-inhibitors-nested-loops" title="Link to this heading">#</a></h2>
<p>Only the innermost loop of the following example is vectorized</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>      for (int i = 0; i &lt; n; i++) {
          for (int j = 0; j &lt; n; j++) {
               a[i][j] += b[i][j];
          }  
      }
</pre></div>
</div>
<p>The exception is if an original outer loop is transformed into an inner loop as the result of compiler optimizations.</p>
</section>
<section id="automatic-vectorization-and-vectorization-inhibitors-function-calls">
<h2><span class="section-number">14.24. </span>Automatic vectorization and vectorization inhibitors, function calls<a class="headerlink" href="#automatic-vectorization-and-vectorization-inhibitors-function-calls" title="Link to this heading">#</a></h2>
<p>Calls to programmer defined functions ruin vectorization. However, calls to intrinsic functions like
<span class="math notranslate nohighlight">\(\sin{x}\)</span>, <span class="math notranslate nohighlight">\(\cos{x}\)</span>, <span class="math notranslate nohighlight">\(\exp{x}\)</span> etc are allowed since they are normally efficiently vectorized.
The following example is fully vectorizable</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>      for (int i = 0; i &lt; n; i++) {
          a[i] = log10(i)*cos(i);
      }
</pre></div>
</div>
<p>Similarly, <strong>inline</strong> functions defined by the programmer, allow for vectorization since the function statements are glued into the actual place where the function is called.</p>
</section>
<section id="automatic-vectorization-and-vectorization-inhibitors-data-dependencies">
<h2><span class="section-number">14.25. </span>Automatic vectorization and vectorization inhibitors, data dependencies<a class="headerlink" href="#automatic-vectorization-and-vectorization-inhibitors-data-dependencies" title="Link to this heading">#</a></h2>
<p>One has to keep in mind that vectorization changes the order of operations inside a loop. A so-called
read-after-write statement with an explicit flow dependency cannot be vectorized. The following code</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>      double b = 15.;
      for (int i = 1; i &lt; n; i++) {
          a[i] = a[i-1] + b;
      }
</pre></div>
</div>
<p>is an example of flow dependency and results in wrong numerical results if vectorized. For a scalar operation, the value <span class="math notranslate nohighlight">\(a[i-1]\)</span> computed during the iteration is loaded into the right-hand side and the results are fine. In vector mode however, with a vector length of four, the values <span class="math notranslate nohighlight">\(a[0]\)</span>, <span class="math notranslate nohighlight">\(a[1]\)</span>, <span class="math notranslate nohighlight">\(a[2]\)</span> and <span class="math notranslate nohighlight">\(a[3]\)</span> from the previous loop will be loaded into the right-hand side and produce wrong results. That is, we have</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>       a[1] = a[0] + b;
       a[2] = a[1] + b;
       a[3] = a[2] + b;
       a[4] = a[3] + b;
</pre></div>
</div>
<p>and if the two first iterations are  executed at the same by the SIMD instruction, the value of say <span class="math notranslate nohighlight">\(a[1]\)</span> could be used by the second iteration before it has been calculated by the first iteration, leading thereby to wrong results.</p>
</section>
<section id="automatic-vectorization-and-vectorization-inhibitors-more-data-dependencies">
<h2><span class="section-number">14.26. </span>Automatic vectorization and vectorization inhibitors, more data dependencies<a class="headerlink" href="#automatic-vectorization-and-vectorization-inhibitors-more-data-dependencies" title="Link to this heading">#</a></h2>
<p>On the other hand,  a so-called
write-after-read statement can be vectorized. The following code</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>      double b = 15.;
      for (int i = 1; i &lt; n; i++) {
          a[i-1] = a[i] + b;
      }
</pre></div>
</div>
<p>is an example of flow dependency that can be vectorized since no iteration with a higher value of <span class="math notranslate nohighlight">\(i\)</span>
can complete before an iteration with a lower value of <span class="math notranslate nohighlight">\(i\)</span>. However, such code leads to problems with parallelization.</p>
</section>
<section id="automatic-vectorization-and-vectorization-inhibitors-memory-stride">
<h2><span class="section-number">14.27. </span>Automatic vectorization and vectorization inhibitors, memory stride<a class="headerlink" href="#automatic-vectorization-and-vectorization-inhibitors-memory-stride" title="Link to this heading">#</a></h2>
<p>For C++ programmers  it is also worth keeping in mind that an array notation is preferred to the more compact use of pointers to access array elements. The compiler can often not tell if it is safe to vectorize the code.</p>
<p>When dealing with arrays, you should also avoid memory stride, since this slows down considerably vectorization. When you access array element, write for example the inner loop to vectorize using unit stride, that is, access successively the next array element in memory, as shown here</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>      for (int i = 0; i &lt; n; i++) {
          for (int j = 0; j &lt; n; j++) {
               a[i][j] += b[i][j];
          }  
      }
</pre></div>
</div>
</section>
<section id="memory-management">
<h2><span class="section-number">14.28. </span>Memory management<a class="headerlink" href="#memory-management" title="Link to this heading">#</a></h2>
<p>The main memory contains the program data</p>
<ol class="arabic simple">
<li><p>Cache memory contains a copy of the main memory data</p></li>
<li><p>Cache is faster but consumes more space and power. It is normally assumed to be much faster than main memory</p></li>
<li><p>Registers contain working data only</p></li>
</ol>
<ul class="simple">
<li><p>Modern CPUs perform most or all operations only on data in register</p></li>
</ul>
<ol class="arabic simple" start="4">
<li><p>Multiple Cache memories contain a copy of the main memory data</p></li>
</ol>
<ul class="simple">
<li><p>Cache items accessed by their address in main memory</p></li>
<li><p>L1 cache is the fastest but has the least capacity</p></li>
<li><p>L2, L3 provide intermediate performance/size tradeoffs</p></li>
</ul>
<p>Loads and stores to memory can be as important as floating point operations when we measure performance.</p>
</section>
<section id="memory-and-communication">
<h2><span class="section-number">14.29. </span>Memory and communication<a class="headerlink" href="#memory-and-communication" title="Link to this heading">#</a></h2>
<ol class="arabic simple">
<li><p>Most communication in a computer is carried out in chunks, blocks of bytes of data that move together</p></li>
<li><p>In the memory hierarchy, data moves between memory and cache, and between different levels of cache, in groups called lines</p></li>
</ol>
<ul class="simple">
<li><p>Lines are typically 64-128 bytes, or 8-16 double precision words</p></li>
<li><p>Even if you do not use the data, it is moved and occupies space in the cache</p></li>
</ul>
<p>Many of these  performance features are not captured in most programming languages.</p>
</section>
<section id="measuring-performance">
<h2><span class="section-number">14.30. </span>Measuring performance<a class="headerlink" href="#measuring-performance" title="Link to this heading">#</a></h2>
<p>How do we measure performance? What is wrong with this code to time a loop?</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>      clock_t start, finish;
      start = clock();
      for (int j = 0; j &lt; i; j++) {
        a[j] = b[j]+b[j]*c[j];
      }
      finish = clock();
      double timeused = (double) (finish - start)/(CLOCKS_PER_SEC );
</pre></div>
</div>
</section>
<section id="problems-with-measuring-time">
<h2><span class="section-number">14.31. </span>Problems with measuring time<a class="headerlink" href="#problems-with-measuring-time" title="Link to this heading">#</a></h2>
<ol class="arabic simple">
<li><p>Timers are not infinitely accurate</p></li>
<li><p>All clocks have a granularity, the minimum time that they can measure</p></li>
<li><p>The error in a time measurement, even if everything is perfect, may be the size of this granularity (sometimes called a clock tick)</p></li>
<li><p>Always know what your clock granularity is</p></li>
<li><p>Ensure that your measurement is for a long enough duration (say 100 times the <strong>tick</strong>)</p></li>
</ol>
</section>
<section id="problems-with-cold-start">
<h2><span class="section-number">14.32. </span>Problems with cold start<a class="headerlink" href="#problems-with-cold-start" title="Link to this heading">#</a></h2>
<p>What happens when the code is executed? The assumption is that the code is ready to
execute. But</p>
<ol class="arabic simple">
<li><p>Code may still be on disk, and not even read into memory.</p></li>
<li><p>Data may be in slow memory rather than fast (which may be wrong or right for what you are measuring)</p></li>
<li><p>Multiple tests often necessary to ensure that cold start effects are not present</p></li>
<li><p>Special effort often required to ensure data in the intended part of the memory hierarchy.</p></li>
</ol>
</section>
<section id="problems-with-smart-compilers">
<h2><span class="section-number">14.33. </span>Problems with smart compilers<a class="headerlink" href="#problems-with-smart-compilers" title="Link to this heading">#</a></h2>
<ol class="arabic simple">
<li><p>If the result of the computation is not used, the compiler may eliminate the code</p></li>
<li><p>Performance will look impossibly fantastic</p></li>
<li><p>Even worse, eliminate some of the code so the performance looks plausible</p></li>
<li><p>Ensure that the results are (or may be) used.</p></li>
</ol>
</section>
<section id="problems-with-interference">
<h2><span class="section-number">14.34. </span>Problems with interference<a class="headerlink" href="#problems-with-interference" title="Link to this heading">#</a></h2>
<ol class="arabic simple">
<li><p>Other activities are sharing your processor</p></li>
</ol>
<ul class="simple">
<li><p>Operating system, system demons, other users</p></li>
<li><p>Some parts of the hardware do not always perform with exactly the same performance</p></li>
</ul>
<ol class="arabic simple" start="2">
<li><p>Make multiple tests and report</p></li>
<li><p>Easy choices include</p></li>
</ol>
<ul class="simple">
<li><p>Average tests represent what users might observe over time</p></li>
</ul>
</section>
<section id="problems-with-measuring-performance">
<h2><span class="section-number">14.35. </span>Problems with measuring performance<a class="headerlink" href="#problems-with-measuring-performance" title="Link to this heading">#</a></h2>
<ol class="arabic simple">
<li><p>Accurate, reproducible performance measurement is hard</p></li>
<li><p>Think carefully about your experiment:</p></li>
<li><p>What is it, precisely, that you want to measure?</p></li>
<li><p>How representative is your test to the situation that you are trying to measure?</p></li>
</ol>
</section>
<section id="thomas-algorithm-for-tridiagonal-linear-algebra-equations">
<h2><span class="section-number">14.36. </span>Thomas algorithm for tridiagonal linear algebra equations<a class="headerlink" href="#thomas-algorithm-for-tridiagonal-linear-algebra-equations" title="Link to this heading">#</a></h2>
<div class="math notranslate nohighlight">
\[\begin{split}
\left( \begin{array}{ccccc}
        b_0 &amp; c_0 &amp;        &amp;         &amp;         \\
	a_0 &amp;  b_1 &amp;  c_1    &amp;         &amp;         \\
	   &amp;    &amp; \ddots  &amp;         &amp;         \\
	      &amp;	    &amp; a_{m-3} &amp; b_{m-2} &amp; c_{m-2} \\
	         &amp;    &amp;         &amp; a_{m-2} &amp; b_{m-1}
   \end{array} \right)
\left( \begin{array}{c}
       x_0     \\
       x_1     \\
       \vdots  \\
       x_{m-2} \\
       x_{m-1}
   \end{array} \right)=\left( \begin{array}{c}
       f_0     \\
       f_1     \\
       \vdots  \\
       f_{m-2} \\
       f_{m-1} \\
   \end{array} \right)
\end{split}\]</div>
</section>
<section id="thomas-algorithm-forward-substitution">
<h2><span class="section-number">14.37. </span>Thomas algorithm, forward substitution<a class="headerlink" href="#thomas-algorithm-forward-substitution" title="Link to this heading">#</a></h2>
<p>The first step is to multiply the first row by <span class="math notranslate nohighlight">\(a_0/b_0\)</span> and subtract it from the second row.  This is known as the forward substitution step. We obtain then</p>
<div class="math notranslate nohighlight">
\[
a_i = 0,
\]</div>
<div class="math notranslate nohighlight">
\[
b_i = b_i - \frac{a_{i-1}}{b_{i-1}}c_{i-1},
\]</div>
<p>and</p>
<div class="math notranslate nohighlight">
\[
f_i = f_i - \frac{a_{i-1}}{b_{i-1}}f_{i-1}.
\]</div>
<p>At this point the simplified equation, with only an upper triangular matrix takes the form</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\left( \begin{array}{ccccc}
    b_0 &amp; c_0 &amp;        &amp;         &amp;         \\
       &amp; b_1 &amp;  c_1    &amp;         &amp;         \\
          &amp;    &amp; \ddots &amp;         &amp;         \\
	     &amp;     &amp;        &amp; b_{m-2} &amp; c_{m-2} \\
	        &amp;    &amp;        &amp;         &amp; b_{m-1}
   \end{array} \right)\left( \begin{array}{c}
       x_0     \\
       x_1     \\
       \vdots  \\
       x_{m-2} \\
       x_{m-1}
   \end{array} \right)=\left( \begin{array}{c}
       f_0     \\
       f_1     \\
       \vdots  \\
       f_{m-2} \\
       f_{m-1} \\
   \end{array} \right)
\end{split}\]</div>
</section>
<section id="thomas-algorithm-backward-substitution">
<h2><span class="section-number">14.38. </span>Thomas algorithm, backward substitution<a class="headerlink" href="#thomas-algorithm-backward-substitution" title="Link to this heading">#</a></h2>
<p>The next step is  the backward substitution step.  The last row is multiplied by <span class="math notranslate nohighlight">\(c_{N-3}/b_{N-2}\)</span> and subtracted from the second to last row, thus eliminating <span class="math notranslate nohighlight">\(c_{N-3}\)</span> from the last row.  The general backward substitution procedure is</p>
<div class="math notranslate nohighlight">
\[
c_i = 0,
\]</div>
<p>and</p>
<div class="math notranslate nohighlight">
\[
f_{i-1} = f_{i-1} - \frac{c_{i-1}}{b_i}f_i
\]</div>
<p>All that ramains to be computed is the solution, which is the very straight forward process of</p>
<div class="math notranslate nohighlight">
\[
x_i = \frac{f_i}{b_i}
\]</div>
</section>
<section id="thomas-algorithm-and-counting-of-operations-floating-point-and-memory">
<h2><span class="section-number">14.39. </span>Thomas algorithm and counting of operations (floating point and memory)<a class="headerlink" href="#thomas-algorithm-and-counting-of-operations-floating-point-and-memory" title="Link to this heading">#</a></h2>
<table border="1">
<thead>
<tr><th align="center">   Operation   </th> <th align="center">Floating Point</th> </tr>
</thead>
<tbody>
<tr><td align="center">   Memory Reads       </td> <td align="center">   $14(N-2)$         </td> </tr>
<tr><td align="center">   Memory Writes      </td> <td align="center">   $4(N-2)$          </td> </tr>
<tr><td align="center">   Subtractions       </td> <td align="center">   $3(N-2)$          </td> </tr>
<tr><td align="center">   Multiplications    </td> <td align="center">   $3(N-2)$          </td> </tr>
<tr><td align="center">   Divisions          </td> <td align="center">   $4(N-2)$          </td> </tr>
</tbody>
</table><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>    // Forward substitution    
    // Note that we can simplify by precalculating a[i-1]/b[i-1]
      for (int i=1; i &lt; n; i++) {
         b[i] = b[i] - (a[i-1]*c[i-1])/b[i-1];
         f[i] = g[i] - (a[i-1]*f[i-1])/b[i-1];
      }
      x[n-1] = f[n-1] / b[n-1];
      // Backwards substitution                                                           
      for (int i = n-2; i &gt;= 0; i--) {
         f[i] = f[i] - c[i]*f[i+1]/b[i+1];
         x[i] = f[i]/b[i];
      }
</pre></div>
</div>
</section>
<section id="example-transpose-of-a-matrix">
<h2><span class="section-number">14.40. </span><a class="reference external" href="https://github.com/CompPhysics/ComputationalPhysicsMSU/blob/master/doc/Programs/LecturePrograms/programs/Classes/cpp/program8.cpp">Example: Transpose of a matrix</a><a class="headerlink" href="#example-transpose-of-a-matrix" title="Link to this heading">#</a></h2>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>    #include &lt;cstdlib&gt;
    #include &lt;iostream&gt;
    #include &lt;cmath&gt;
    #include &lt;iomanip&gt;
    #include &quot;time.h&quot;
    
    using namespace std; // note use of namespace
    int main (int argc, char* argv[])
    {
      // read in dimension of square matrix
      int n = atoi(argv[1]);
      double **A, **B;
      // Allocate space for the two matrices
      A = new double*[n]; B = new double*[n];
      for (int i = 0; i &lt; n; i++){
        A[i] = new double[n];
        B[i] = new double[n];
      }
      // Set up values for matrix A
      for (int i = 0; i &lt; n; i++){
        for (int j = 0; j &lt; n; j++) {
          A[i][j] =  cos(i*1.0)*sin(j*3.0);
        }
      }
      clock_t start, finish;
      start = clock();
      // Then compute the transpose
      for (int i = 0; i &lt; n; i++){
        for (int j = 0; j &lt; n; j++) {
          B[i][j]= A[j][i];
        }
      }
    
      finish = clock();
      double timeused = (double) (finish - start)/(CLOCKS_PER_SEC );
      cout &lt;&lt; setiosflags(ios::showpoint | ios::uppercase);
      cout &lt;&lt; setprecision(10) &lt;&lt; setw(20) &lt;&lt; &quot;Time used  for setting up transpose of matrix=&quot; &lt;&lt; timeused  &lt;&lt; endl;
    
      // Free up space
      for (int i = 0; i &lt; n; i++){
        delete[] A[i];
        delete[] B[i];
      }
      delete[] A;
      delete[] B;
      return 0;
    }
</pre></div>
</div>
</section>
<section id="matrix-matrix-multiplication">
<h2><span class="section-number">14.41. </span><a class="reference external" href="https://github.com/CompPhysics/ComputationalPhysicsMSU/blob/master/doc/Programs/LecturePrograms/programs/Classes/cpp/program9.cpp">Matrix-matrix multiplication</a><a class="headerlink" href="#matrix-matrix-multiplication" title="Link to this heading">#</a></h2>
<p>This the matrix-matrix multiplication code with plain c++ memory allocation. It computes at the end the Frobenius norm.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>    #include &lt;cstdlib&gt;
    #include &lt;iostream&gt;
    #include &lt;cmath&gt;
    #include &lt;iomanip&gt;
    #include &quot;time.h&quot;
    
    using namespace std; // note use of namespace
    int main (int argc, char* argv[])
    {
      // read in dimension of square matrix
      int n = atoi(argv[1]);
      double s = 1.0/sqrt( (double) n);
      double **A, **B, **C;
      // Start timing
      clock_t start, finish;
      start = clock();
      // Allocate space for the two matrices
      A = new double*[n]; B = new double*[n]; C = new double*[n];
      for (int i = 0; i &lt; n; i++){
        A[i] = new double[n];
        B[i] = new double[n];
        C[i] = new double[n];
      }
      // Set up values for matrix A and B and zero matrix C
      for (int i = 0; i &lt; n; i++){
        for (int j = 0; j &lt; n; j++) {
          double angle = 2.0*M_PI*i*j/ (( double ) n);
          A[i][j] = s * ( sin ( angle ) + cos ( angle ) );
          B[j][i] =  A[i][j];
        }
      }
      // Then perform the matrix-matrix multiplication
      for (int i = 0; i &lt; n; i++){
        for (int j = 0; j &lt; n; j++) {
          double sum = 0.0;
           for (int k = 0; k &lt; n; k++) {
               sum += B[i][k]*A[k][j];
           }
           C[i][j] = sum;
        }
      }
      // Compute now the Frobenius norm
      double Fsum = 0.0;
      for (int i = 0; i &lt; n; i++){
        for (int j = 0; j &lt; n; j++) {
          Fsum += C[i][j]*C[i][j];
        }
      }
      Fsum = sqrt(Fsum);
      finish = clock();
      double timeused = (double) (finish - start)/(CLOCKS_PER_SEC );
      cout &lt;&lt; setiosflags(ios::showpoint | ios::uppercase);
      cout &lt;&lt; setprecision(10) &lt;&lt; setw(20) &lt;&lt; &quot;Time used  for matrix-matrix multiplication=&quot; &lt;&lt; timeused  &lt;&lt; endl;
      cout &lt;&lt; &quot;  Frobenius norm  = &quot; &lt;&lt; Fsum &lt;&lt; endl;
      // Free up space
      for (int i = 0; i &lt; n; i++){
        delete[] A[i];
        delete[] B[i];
        delete[] C[i];
      }
      delete[] A;
      delete[] B;
      delete[] C;
      return 0;
    }
</pre></div>
</div>
</section>
<section id="how-do-we-define-speedup-simplest-form">
<h2><span class="section-number">14.42. </span>How do we define speedup? Simplest form<a class="headerlink" href="#how-do-we-define-speedup-simplest-form" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Speedup measures the ratio of performance between two objects</p></li>
<li><p>Versions of same code, with different number of processors</p></li>
<li><p>Serial and vector versions</p></li>
<li><p>Try different programing languages, c++ and Fortran</p></li>
<li><p>Two algorithms computing the <strong>same</strong> result</p></li>
</ul>
</section>
<section id="how-do-we-define-speedup-correct-baseline">
<h2><span class="section-number">14.43. </span>How do we define speedup? Correct baseline<a class="headerlink" href="#how-do-we-define-speedup-correct-baseline" title="Link to this heading">#</a></h2>
<p>The key is choosing the correct baseline for comparison</p>
<ul class="simple">
<li><p>For our serial vs. vectorization examples, using compiler-provided vectorization, the baseline is simple; the same code, with vectorization turned off</p></li>
<li><p>For parallel applications, this is much harder:</p></li>
<li><p>Choice of algorithm, decomposition, performance of baseline case etc.</p></li>
</ul>
</section>
<section id="parallel-speedup">
<h2><span class="section-number">14.44. </span>Parallel  speedup<a class="headerlink" href="#parallel-speedup" title="Link to this heading">#</a></h2>
<p>For parallel applications, speedup  is typically defined as</p>
<ul class="simple">
<li><p>Speedup <span class="math notranslate nohighlight">\(=T_1/T_p\)</span></p></li>
</ul>
<p>Here  <span class="math notranslate nohighlight">\(T_1\)</span> is the time on one processor and <span class="math notranslate nohighlight">\(T_p\)</span> is the time using <span class="math notranslate nohighlight">\(p\)</span> processors.</p>
<ul class="simple">
<li><p>Can the speedup become larger than  <span class="math notranslate nohighlight">\(p\)</span>? That means using <span class="math notranslate nohighlight">\(p\)</span> processors is more than <span class="math notranslate nohighlight">\(p\)</span> times faster than using one processor.</p></li>
</ul>
</section>
<section id="speedup-and-memory">
<h2><span class="section-number">14.45. </span>Speedup and memory<a class="headerlink" href="#speedup-and-memory" title="Link to this heading">#</a></h2>
<p>The speedup on <span class="math notranslate nohighlight">\(p\)</span> processors can
be greater than <span class="math notranslate nohighlight">\(p\)</span> if memory usage is optimal!
Consider the case of a memorybound computation with <span class="math notranslate nohighlight">\(M\)</span> words of memory</p>
<ul class="simple">
<li><p>If <span class="math notranslate nohighlight">\(M/p\)</span> fits into cache while <span class="math notranslate nohighlight">\(M\)</span> does not, the time to access memory will be different in the two cases:</p></li>
<li><p><span class="math notranslate nohighlight">\(T_1\)</span> uses the main memory bandwidth</p></li>
<li><p><span class="math notranslate nohighlight">\(T_p\)</span> uses the appropriate cache bandwidth</p></li>
</ul>
</section>
<section id="upper-bounds-on-speedup">
<h2><span class="section-number">14.46. </span>Upper bounds on speedup<a class="headerlink" href="#upper-bounds-on-speedup" title="Link to this heading">#</a></h2>
<p>Assume that almost all parts of a code are perfectly
parallelizable (fraction <span class="math notranslate nohighlight">\(f\)</span>). The remainder,
fraction <span class="math notranslate nohighlight">\((1-f)\)</span> cannot be parallelized at all.</p>
<p>That is, there is work that takes time <span class="math notranslate nohighlight">\(W\)</span> on one process; a fraction <span class="math notranslate nohighlight">\(f\)</span> of that work will take
time <span class="math notranslate nohighlight">\(Wf/p\)</span> on <span class="math notranslate nohighlight">\(p\)</span> processors.</p>
<ul class="simple">
<li><p>What is the maximum possible speedup as a function of <span class="math notranslate nohighlight">\(f\)</span>?</p></li>
</ul>
</section>
<section id="amdahl-s-law">
<h2><span class="section-number">14.47. </span>Amdahl’s law<a class="headerlink" href="#amdahl-s-law" title="Link to this heading">#</a></h2>
<p>On one processor we have</p>
<div class="math notranslate nohighlight">
\[
T_1 = (1-f)W + fW = W
\]</div>
<p>On <span class="math notranslate nohighlight">\(p\)</span> processors we have</p>
<div class="math notranslate nohighlight">
\[
T_p = (1-f)W + \frac{fW}{p},
\]</div>
<p>resulting in a speedup of</p>
<div class="math notranslate nohighlight">
\[
\frac{T_1}{T_p} = \frac{W}{(1-f)W+fW/p}
\]</div>
<p>As <span class="math notranslate nohighlight">\(p\)</span> goes to infinity, <span class="math notranslate nohighlight">\(fW/p\)</span> goes to zero, and the maximum speedup is</p>
<div class="math notranslate nohighlight">
\[
\frac{1}{1-f},
\]</div>
<p>meaning that if
if <span class="math notranslate nohighlight">\(f = 0.99\)</span> (all but <span class="math notranslate nohighlight">\(1\%\)</span> parallelizable), the maximum speedup
is <span class="math notranslate nohighlight">\(1/(1-.99)=100\)</span>!</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="boltzmannmachines.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">13. </span>Boltzmann Machines</p>
      </div>
    </a>
    <a class="right-next"
       href="parallelization.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">15. </span>Parallelization with MPI and OpenMPI</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#optimization-and-profiling">14.1. Optimization and profiling</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#more-on-optimization">14.2. More on optimization</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">14.3. Optimization and profiling</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#optimization-and-debugging">14.4. Optimization and debugging</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#other-hints">14.5. Other hints</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#vectorization-and-the-basic-idea-behind-parallel-computing">14.6. Vectorization and the basic idea behind parallel computing</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#a-rough-classification-of-hardware-models">14.7. A rough classification of hardware models</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#shared-memory-and-distributed-memory">14.8. Shared memory and distributed memory</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#different-parallel-programming-paradigms">14.9. Different parallel programming paradigms</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">14.10. Different parallel programming paradigms</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-is-vectorization">14.11. What is vectorization?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#number-of-elements-that-can-acted-upon">14.12. Number of elements that can acted upon</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#number-of-elements-that-can-acted-upon-examples">14.13. Number of elements that can acted upon, examples</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#operation-counts-for-scalar-operation">14.14. Operation counts for scalar operation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">14.15. Number of elements that can acted upon, examples</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#number-of-operations-when-vectorized">14.16. Number of operations when vectorized</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#a-simple-test-case-with-and-without-vectorization">14.17. A simple test case with and without vectorization</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#compiling-with-and-without-vectorization">14.18. Compiling with and without vectorization</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#compiling-with-and-without-vectorization-using-clang">14.19. Compiling with and without vectorization using clang</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#automatic-vectorization-and-vectorization-inhibitors-criteria">14.20. Automatic vectorization and vectorization inhibitors, criteria</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#automatic-vectorization-and-vectorization-inhibitors-exit-criteria">14.21. Automatic vectorization and vectorization inhibitors, exit criteria</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#automatic-vectorization-and-vectorization-inhibitors-straight-line-code">14.22. Automatic vectorization and vectorization inhibitors, straight-line code</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#automatic-vectorization-and-vectorization-inhibitors-nested-loops">14.23. Automatic vectorization and vectorization inhibitors, nested loops</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#automatic-vectorization-and-vectorization-inhibitors-function-calls">14.24. Automatic vectorization and vectorization inhibitors, function calls</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#automatic-vectorization-and-vectorization-inhibitors-data-dependencies">14.25. Automatic vectorization and vectorization inhibitors, data dependencies</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#automatic-vectorization-and-vectorization-inhibitors-more-data-dependencies">14.26. Automatic vectorization and vectorization inhibitors, more data dependencies</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#automatic-vectorization-and-vectorization-inhibitors-memory-stride">14.27. Automatic vectorization and vectorization inhibitors, memory stride</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#memory-management">14.28. Memory management</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#memory-and-communication">14.29. Memory and communication</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#measuring-performance">14.30. Measuring performance</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#problems-with-measuring-time">14.31. Problems with measuring time</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#problems-with-cold-start">14.32. Problems with cold start</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#problems-with-smart-compilers">14.33. Problems with smart compilers</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#problems-with-interference">14.34. Problems with interference</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#problems-with-measuring-performance">14.35. Problems with measuring performance</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#thomas-algorithm-for-tridiagonal-linear-algebra-equations">14.36. Thomas algorithm for tridiagonal linear algebra equations</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#thomas-algorithm-forward-substitution">14.37. Thomas algorithm, forward substitution</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#thomas-algorithm-backward-substitution">14.38. Thomas algorithm, backward substitution</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#thomas-algorithm-and-counting-of-operations-floating-point-and-memory">14.39. Thomas algorithm and counting of operations (floating point and memory)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#example-transpose-of-a-matrix">14.40. Example: Transpose of a matrix</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#matrix-matrix-multiplication">14.41. Matrix-matrix multiplication</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-do-we-define-speedup-simplest-form">14.42. How do we define speedup? Simplest form</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-do-we-define-speedup-correct-baseline">14.43. How do we define speedup? Correct baseline</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#parallel-speedup">14.44. Parallel  speedup</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#speedup-and-memory">14.45. Speedup and memory</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#upper-bounds-on-speedup">14.46. Upper bounds on speedup</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#amdahl-s-law">14.47. Amdahl’s law</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Morten Hjorth-Jensen
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="_static/scripts/bootstrap.js?digest=26a4bc78f4c0ddb94549"></script>
<script defer src="_static/scripts/pydata-sphinx-theme.js?digest=26a4bc78f4c0ddb94549"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>